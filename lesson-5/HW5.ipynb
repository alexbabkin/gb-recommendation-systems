{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Для работы с матрицами\n",
    "from scipy.sparse import csr_matrix, coo_matrix\n",
    "\n",
    "# Матричная факторизация\n",
    "from implicit.als import AlternatingLeastSquares\n",
    "from implicit.nearest_neighbours import bm25_weight, tfidf_weight\n",
    "\n",
    "from lightfm import LightFM\n",
    "from lightfm.evaluation import precision_at_k, recall_at_k\n",
    "\n",
    "# Функции из 1-ого вебинара\n",
    "import os, sys\n",
    "\n",
    "module_path = os.path.abspath(os.path.join(os.pardir))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    \n",
    "# from src.metrics import precision_at_k, recall_at_k\n",
    "from webinar5.utils import prefilter_items\n",
    "\n",
    "from parameters.param_iterator import param_iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>basket_id</th>\n",
       "      <th>day</th>\n",
       "      <th>item_id</th>\n",
       "      <th>quantity</th>\n",
       "      <th>sales_value</th>\n",
       "      <th>store_id</th>\n",
       "      <th>retail_disc</th>\n",
       "      <th>trans_time</th>\n",
       "      <th>week_no</th>\n",
       "      <th>coupon_disc</th>\n",
       "      <th>coupon_match_disc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2375</td>\n",
       "      <td>26984851472</td>\n",
       "      <td>1</td>\n",
       "      <td>1004906</td>\n",
       "      <td>1</td>\n",
       "      <td>1.39</td>\n",
       "      <td>364</td>\n",
       "      <td>-0.60</td>\n",
       "      <td>1631</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2375</td>\n",
       "      <td>26984851472</td>\n",
       "      <td>1</td>\n",
       "      <td>1033142</td>\n",
       "      <td>1</td>\n",
       "      <td>0.82</td>\n",
       "      <td>364</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1631</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2375</td>\n",
       "      <td>26984851472</td>\n",
       "      <td>1</td>\n",
       "      <td>1036325</td>\n",
       "      <td>1</td>\n",
       "      <td>0.99</td>\n",
       "      <td>364</td>\n",
       "      <td>-0.30</td>\n",
       "      <td>1631</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2375</td>\n",
       "      <td>26984851472</td>\n",
       "      <td>1</td>\n",
       "      <td>1082185</td>\n",
       "      <td>1</td>\n",
       "      <td>1.21</td>\n",
       "      <td>364</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1631</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2375</td>\n",
       "      <td>26984851472</td>\n",
       "      <td>1</td>\n",
       "      <td>8160430</td>\n",
       "      <td>1</td>\n",
       "      <td>1.50</td>\n",
       "      <td>364</td>\n",
       "      <td>-0.39</td>\n",
       "      <td>1631</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id    basket_id  day  item_id  quantity  sales_value  store_id  \\\n",
       "0     2375  26984851472    1  1004906         1         1.39       364   \n",
       "1     2375  26984851472    1  1033142         1         0.82       364   \n",
       "2     2375  26984851472    1  1036325         1         0.99       364   \n",
       "3     2375  26984851472    1  1082185         1         1.21       364   \n",
       "4     2375  26984851472    1  8160430         1         1.50       364   \n",
       "\n",
       "   retail_disc  trans_time  week_no  coupon_disc  coupon_match_disc  \n",
       "0        -0.60        1631        1          0.0                0.0  \n",
       "1         0.00        1631        1          0.0                0.0  \n",
       "2        -0.30        1631        1          0.0                0.0  \n",
       "3         0.00        1631        1          0.0                0.0  \n",
       "4        -0.39        1631        1          0.0                0.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('./retail_train.csv')\n",
    "\n",
    "item_features = pd.read_csv('./product.csv')\n",
    "user_features = pd.read_csv('./hh_demographic.csv')\n",
    "\n",
    "# column processing\n",
    "item_features.columns = [col.lower() for col in item_features.columns]\n",
    "user_features.columns = [col.lower() for col in user_features.columns]\n",
    "\n",
    "item_features.rename(columns={'product_id': 'item_id'}, inplace=True)\n",
    "user_features.rename(columns={'household_key': 'user_id'}, inplace=True)\n",
    "\n",
    "# train test split\n",
    "test_size_weeks = 3\n",
    "\n",
    "data_train = data[data['week_no'] < data['week_no'].max() - test_size_weeks]\n",
    "data_test = data[data['week_no'] >= data['week_no'].max() - test_size_weeks]\n",
    "\n",
    "data_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>manufacturer</th>\n",
       "      <th>department</th>\n",
       "      <th>brand</th>\n",
       "      <th>commodity_desc</th>\n",
       "      <th>sub_commodity_desc</th>\n",
       "      <th>curr_size_of_product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25671</td>\n",
       "      <td>2</td>\n",
       "      <td>GROCERY</td>\n",
       "      <td>National</td>\n",
       "      <td>FRZN ICE</td>\n",
       "      <td>ICE - CRUSHED/CUBED</td>\n",
       "      <td>22 LB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26081</td>\n",
       "      <td>2</td>\n",
       "      <td>MISC. TRANS.</td>\n",
       "      <td>National</td>\n",
       "      <td>NO COMMODITY DESCRIPTION</td>\n",
       "      <td>NO SUBCOMMODITY DESCRIPTION</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26093</td>\n",
       "      <td>69</td>\n",
       "      <td>PASTRY</td>\n",
       "      <td>Private</td>\n",
       "      <td>BREAD</td>\n",
       "      <td>BREAD:ITALIAN/FRENCH</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26190</td>\n",
       "      <td>69</td>\n",
       "      <td>GROCERY</td>\n",
       "      <td>Private</td>\n",
       "      <td>FRUIT - SHELF STABLE</td>\n",
       "      <td>APPLE SAUCE</td>\n",
       "      <td>50 OZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26355</td>\n",
       "      <td>69</td>\n",
       "      <td>GROCERY</td>\n",
       "      <td>Private</td>\n",
       "      <td>COOKIES/CONES</td>\n",
       "      <td>SPECIALTY COOKIES</td>\n",
       "      <td>14 OZ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   item_id  manufacturer    department     brand            commodity_desc  \\\n",
       "0    25671             2       GROCERY  National                  FRZN ICE   \n",
       "1    26081             2  MISC. TRANS.  National  NO COMMODITY DESCRIPTION   \n",
       "2    26093            69        PASTRY   Private                     BREAD   \n",
       "3    26190            69       GROCERY   Private      FRUIT - SHELF STABLE   \n",
       "4    26355            69       GROCERY   Private             COOKIES/CONES   \n",
       "\n",
       "            sub_commodity_desc curr_size_of_product  \n",
       "0          ICE - CRUSHED/CUBED                22 LB  \n",
       "1  NO SUBCOMMODITY DESCRIPTION                       \n",
       "2         BREAD:ITALIAN/FRENCH                       \n",
       "3                  APPLE SAUCE                50 OZ  \n",
       "4            SPECIALTY COOKIES                14 OZ  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age_desc</th>\n",
       "      <th>marital_status_code</th>\n",
       "      <th>income_desc</th>\n",
       "      <th>homeowner_desc</th>\n",
       "      <th>hh_comp_desc</th>\n",
       "      <th>household_size_desc</th>\n",
       "      <th>kid_category_desc</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>65+</td>\n",
       "      <td>A</td>\n",
       "      <td>35-49K</td>\n",
       "      <td>Homeowner</td>\n",
       "      <td>2 Adults No Kids</td>\n",
       "      <td>2</td>\n",
       "      <td>None/Unknown</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>45-54</td>\n",
       "      <td>A</td>\n",
       "      <td>50-74K</td>\n",
       "      <td>Homeowner</td>\n",
       "      <td>2 Adults No Kids</td>\n",
       "      <td>2</td>\n",
       "      <td>None/Unknown</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25-34</td>\n",
       "      <td>U</td>\n",
       "      <td>25-34K</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>2 Adults Kids</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25-34</td>\n",
       "      <td>U</td>\n",
       "      <td>75-99K</td>\n",
       "      <td>Homeowner</td>\n",
       "      <td>2 Adults Kids</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>45-54</td>\n",
       "      <td>B</td>\n",
       "      <td>50-74K</td>\n",
       "      <td>Homeowner</td>\n",
       "      <td>Single Female</td>\n",
       "      <td>1</td>\n",
       "      <td>None/Unknown</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  age_desc marital_status_code income_desc homeowner_desc      hh_comp_desc  \\\n",
       "0      65+                   A      35-49K      Homeowner  2 Adults No Kids   \n",
       "1    45-54                   A      50-74K      Homeowner  2 Adults No Kids   \n",
       "2    25-34                   U      25-34K        Unknown     2 Adults Kids   \n",
       "3    25-34                   U      75-99K      Homeowner     2 Adults Kids   \n",
       "4    45-54                   B      50-74K      Homeowner     Single Female   \n",
       "\n",
       "  household_size_desc kid_category_desc  user_id  \n",
       "0                   2      None/Unknown        1  \n",
       "1                   2      None/Unknown        7  \n",
       "2                   3                 1        8  \n",
       "3                   4                 2       13  \n",
       "4                   1      None/Unknown       16  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decreased # items from 86865 to 5001\n"
     ]
    }
   ],
   "source": [
    "n_items_before = data_train['item_id'].nunique()\n",
    "\n",
    "data_train_filtered = prefilter_items(data_train, item_features=item_features)\n",
    "\n",
    "n_items_after = data_train_filtered['item_id'].nunique()\n",
    "\n",
    "print('Decreased # items from {} to {}'.format(n_items_before, n_items_after))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Prepare data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Prepare csr train matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>item_id</th>\n",
       "      <th>117847</th>\n",
       "      <th>818981</th>\n",
       "      <th>819255</th>\n",
       "      <th>819308</th>\n",
       "      <th>819400</th>\n",
       "      <th>819487</th>\n",
       "      <th>819590</th>\n",
       "      <th>819594</th>\n",
       "      <th>819840</th>\n",
       "      <th>819845</th>\n",
       "      <th>...</th>\n",
       "      <th>15926775</th>\n",
       "      <th>15926844</th>\n",
       "      <th>15926886</th>\n",
       "      <th>15972074</th>\n",
       "      <th>15972298</th>\n",
       "      <th>15972565</th>\n",
       "      <th>15972790</th>\n",
       "      <th>16100266</th>\n",
       "      <th>16729299</th>\n",
       "      <th>16729415</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 5001 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "item_id  117847    818981    819255    819308    819400    819487    819590    \\\n",
       "user_id                                                                         \n",
       "1             0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "2             0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "3             0.0       0.0       1.0       0.0       0.0       0.0       0.0   \n",
       "4             0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "5             0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "\n",
       "item_id  819594    819840    819845    ...  15926775  15926844  15926886  \\\n",
       "user_id                                ...                                 \n",
       "1             0.0       0.0       0.0  ...       0.0       1.0       0.0   \n",
       "2             0.0       0.0       0.0  ...       0.0       0.0       0.0   \n",
       "3             0.0       0.0       0.0  ...       0.0       0.0       0.0   \n",
       "4             0.0       0.0       0.0  ...       0.0       0.0       0.0   \n",
       "5             0.0       0.0       0.0  ...       0.0       0.0       0.0   \n",
       "\n",
       "item_id  15972074  15972298  15972565  15972790  16100266  16729299  16729415  \n",
       "user_id                                                                        \n",
       "1             0.0       0.0       0.0       0.0       0.0       0.0       0.0  \n",
       "2             0.0       0.0       0.0       0.0       0.0       0.0       0.0  \n",
       "3             0.0       0.0       0.0       0.0       0.0       0.0       0.0  \n",
       "4             0.0       0.0       0.0       0.0       0.0       0.0       0.0  \n",
       "5             0.0       0.0       0.0       0.0       0.0       0.0       0.0  \n",
       "\n",
       "[5 rows x 5001 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_item_matrix = pd.pivot_table(data_train_filtered, \n",
    "                                  index='user_id', columns='item_id', \n",
    "                                  values='quantity', # Можно пробовать другие варианты\n",
    "                                  aggfunc='count', \n",
    "                                  fill_value=0\n",
    "                                 )\n",
    "\n",
    "user_item_matrix = user_item_matrix.astype(float) # необходимый тип матрицы для implicit\n",
    "\n",
    "# переведем в формат saprse matrix\n",
    "sparse_user_item = csr_matrix(user_item_matrix).tocsr()\n",
    "\n",
    "user_item_matrix.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Prepare CSR test matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = data_test[data_test['item_id'].isin(data_train_filtered['item_id'].unique())]\n",
    "\n",
    "test_user_item_matrix = pd.pivot_table(data_test, \n",
    "                                  index='user_id', columns='item_id', \n",
    "                                  values='quantity', # Можно пробоват ьдругие варианты\n",
    "                                  aggfunc='count', \n",
    "                                  fill_value=0\n",
    "                                 )\n",
    "\n",
    "test_user_item_matrix = test_user_item_matrix.astype(float) # необходимый тип матрицы для implicit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "userids = user_item_matrix.index.values\n",
    "itemids = user_item_matrix.columns.values\n",
    "\n",
    "matrix_userids = np.arange(len(userids))\n",
    "matrix_itemids = np.arange(len(itemids))\n",
    "\n",
    "id_to_itemid = dict(zip(matrix_itemids, itemids))\n",
    "id_to_userid = dict(zip(matrix_userids, userids))\n",
    "\n",
    "itemid_to_id = dict(zip(itemids, matrix_itemids))\n",
    "userid_to_id = dict(zip(userids, matrix_userids))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Prepare user and item features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age_desc</th>\n",
       "      <th>marital_status_code</th>\n",
       "      <th>income_desc</th>\n",
       "      <th>homeowner_desc</th>\n",
       "      <th>hh_comp_desc</th>\n",
       "      <th>household_size_desc</th>\n",
       "      <th>kid_category_desc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>65+</td>\n",
       "      <td>A</td>\n",
       "      <td>35-49K</td>\n",
       "      <td>Homeowner</td>\n",
       "      <td>2 Adults No Kids</td>\n",
       "      <td>2</td>\n",
       "      <td>None/Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        age_desc marital_status_code income_desc homeowner_desc  \\\n",
       "user_id                                                           \n",
       "1            65+                   A      35-49K      Homeowner   \n",
       "2            NaN                 NaN         NaN            NaN   \n",
       "3            NaN                 NaN         NaN            NaN   \n",
       "4            NaN                 NaN         NaN            NaN   \n",
       "5            NaN                 NaN         NaN            NaN   \n",
       "\n",
       "             hh_comp_desc household_size_desc kid_category_desc  \n",
       "user_id                                                          \n",
       "1        2 Adults No Kids                   2      None/Unknown  \n",
       "2                     NaN                 NaN               NaN  \n",
       "3                     NaN                 NaN               NaN  \n",
       "4                     NaN                 NaN               NaN  \n",
       "5                     NaN                 NaN               NaN  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_feat = pd.DataFrame(user_item_matrix.index)\n",
    "user_feat = user_feat.merge(user_features, on='user_id', how='left')\n",
    "user_feat.set_index('user_id', inplace=True)\n",
    "user_feat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>manufacturer</th>\n",
       "      <th>department</th>\n",
       "      <th>brand</th>\n",
       "      <th>commodity_desc</th>\n",
       "      <th>sub_commodity_desc</th>\n",
       "      <th>curr_size_of_product</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>item_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>117847</th>\n",
       "      <td>450.0</td>\n",
       "      <td>NUTRITION</td>\n",
       "      <td>National</td>\n",
       "      <td>REFRIGERATED</td>\n",
       "      <td>SOY/RICE MILK</td>\n",
       "      <td>64 OZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818981</th>\n",
       "      <td>194.0</td>\n",
       "      <td>GROCERY</td>\n",
       "      <td>National</td>\n",
       "      <td>COLD CEREAL</td>\n",
       "      <td>ALL FAMILY CEREAL</td>\n",
       "      <td>10.4 OZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>819255</th>\n",
       "      <td>1007.0</td>\n",
       "      <td>MEAT-PCKGD</td>\n",
       "      <td>National</td>\n",
       "      <td>BREAKFAST SAUSAGE/SANDWICHES</td>\n",
       "      <td>ROLLS - PORK</td>\n",
       "      <td>1 LB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>819308</th>\n",
       "      <td>2879.0</td>\n",
       "      <td>MEAT</td>\n",
       "      <td>National</td>\n",
       "      <td>BEEF</td>\n",
       "      <td>CHOICE BEEF</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>819400</th>\n",
       "      <td>584.0</td>\n",
       "      <td>GROCERY</td>\n",
       "      <td>National</td>\n",
       "      <td>DOG FOODS</td>\n",
       "      <td>DOG TREATS (SOFT TREATS)</td>\n",
       "      <td>5.6 OZ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         manufacturer  department     brand                commodity_desc  \\\n",
       "item_id                                                                     \n",
       "117847          450.0   NUTRITION  National                  REFRIGERATED   \n",
       "818981          194.0     GROCERY  National                   COLD CEREAL   \n",
       "819255         1007.0  MEAT-PCKGD  National  BREAKFAST SAUSAGE/SANDWICHES   \n",
       "819308         2879.0        MEAT  National                          BEEF   \n",
       "819400          584.0     GROCERY  National                     DOG FOODS   \n",
       "\n",
       "               sub_commodity_desc curr_size_of_product  \n",
       "item_id                                                 \n",
       "117847              SOY/RICE MILK                64 OZ  \n",
       "818981          ALL FAMILY CEREAL              10.4 OZ  \n",
       "819255               ROLLS - PORK                 1 LB  \n",
       "819308                CHOICE BEEF                       \n",
       "819400   DOG TREATS (SOFT TREATS)               5.6 OZ  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_feat = pd.DataFrame(user_item_matrix.columns)\n",
    "item_feat = item_feat.merge(item_features, on='item_id', how='left')\n",
    "item_feat.set_index('item_id', inplace=True)\n",
    "\n",
    "item_feat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_feat_lightfm = pd.get_dummies(user_feat, columns=user_feat.columns.tolist())\n",
    "item_feat_lightfm = pd.get_dummies(item_feat, columns=item_feat.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model. Iterate over parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_precision_for_parameters(param_grid, k):\n",
    "    res_table = pd.DataFrame(columns=[\"parameters\", f\"train precision@{k}\", f\"test precision@{k}\"])\n",
    "    for param in param_iterator(param_grid, verbose=True):\n",
    "        model = LightFM(random_state=42, **param)\n",
    "        try:\n",
    "            model.fit((sparse_user_item > 0) * 1,  # user-item matrix из 0 и 1\n",
    "                      sample_weight=coo_matrix(user_item_matrix),\n",
    "                      user_features=csr_matrix(user_feat_lightfm.values).tocsr(),\n",
    "                      item_features=csr_matrix(item_feat_lightfm.values).tocsr(),\n",
    "                      epochs=15, \n",
    "                      num_threads=4,\n",
    "                      verbose=False)\n",
    "        except Exception as e:\n",
    "            print(\"Error ocurred, skipping prameter\")\n",
    "            continue\n",
    "    \n",
    "        train_precision = precision_at_k(model, sparse_user_item, \n",
    "                                 user_features=csr_matrix(user_feat_lightfm.values).tocsr(),\n",
    "                                 item_features=csr_matrix(item_feat_lightfm.values).tocsr(),\n",
    "                                 k=k).mean()\n",
    "\n",
    "        test_precision = precision_at_k(model, csr_matrix(test_user_item_matrix).tocsr(), \n",
    "                                 user_features=csr_matrix(user_feat_lightfm.values).tocsr(),\n",
    "                                 item_features=csr_matrix(item_feat_lightfm.values).tocsr(),\n",
    "                                 k=k).mean()\n",
    "\n",
    "        print(f\"Result: train_precision = {train_precision}, test_precision = {test_precision}\")\n",
    "        result = pd.DataFrame([[param, train_precision, test_precision]], columns=[\"parameters\", f\"train precision@{k}\", f\"test precision@{k}\"])\n",
    "        res_table = res_table.append(result)\n",
    "    return res_table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1 of 486\n",
      "Parameters: {'no_components': 16, 'learning_rate': 0.05, 'item_alpha': 0.001, 'user_alpha': 0.001, 'max_sampled': 5, 'loss': 'warp'}\n",
      "Result: train_precision = 0.27785342931747437, test_precision = 0.002295253099873662\n",
      "Step 2 of 486\n",
      "Parameters: {'no_components': 16, 'learning_rate': 0.05, 'item_alpha': 0.001, 'user_alpha': 0.001, 'max_sampled': 5, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.3527432978153229, test_precision = 0.0019822639878839254\n",
      "Step 3 of 486\n",
      "Parameters: {'no_components': 16, 'learning_rate': 0.05, 'item_alpha': 0.001, 'user_alpha': 0.001, 'max_sampled': 10, 'loss': 'warp'}\n",
      "Result: train_precision = 0.285142183303833, test_precision = 0.0017736046575009823\n",
      "Step 4 of 486\n",
      "Parameters: {'no_components': 16, 'learning_rate': 0.05, 'item_alpha': 0.001, 'user_alpha': 0.001, 'max_sampled': 10, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.35034042596817017, test_precision = 0.000938967103138566\n",
      "Step 5 of 486\n",
      "Parameters: {'no_components': 16, 'learning_rate': 0.05, 'item_alpha': 0.001, 'user_alpha': 0.001, 'max_sampled': 15, 'loss': 'warp'}\n",
      "Result: train_precision = 0.2873047888278961, test_precision = 0.0017736046575009823\n",
      "Step 6 of 486\n",
      "Parameters: {'no_components': 16, 'learning_rate': 0.05, 'item_alpha': 0.001, 'user_alpha': 0.001, 'max_sampled': 15, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.3523428440093994, test_precision = 0.0012519562151283026\n",
      "Step 7 of 486\n",
      "Parameters: {'no_components': 16, 'learning_rate': 0.05, 'item_alpha': 0.001, 'user_alpha': 0.01, 'max_sampled': 5, 'loss': 'warp'}\n",
      "Result: train_precision = 0.2893872857093811, test_precision = 0.0013562858803197742\n",
      "Step 8 of 486\n",
      "Parameters: {'no_components': 16, 'learning_rate': 0.05, 'item_alpha': 0.001, 'user_alpha': 0.01, 'max_sampled': 5, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.20056068897247314, test_precision = 0.0010432967683300376\n",
      "Step 9 of 486\n",
      "Parameters: {'no_components': 16, 'learning_rate': 0.05, 'item_alpha': 0.001, 'user_alpha': 0.01, 'max_sampled': 10, 'loss': 'warp'}\n",
      "Result: train_precision = 0.29195037484169006, test_precision = 0.0014606156619265676\n",
      "Step 10 of 486\n",
      "Parameters: {'no_components': 16, 'learning_rate': 0.05, 'item_alpha': 0.001, 'user_alpha': 0.01, 'max_sampled': 10, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.20032040774822235, test_precision = 0.002086593536660075\n",
      "Step 11 of 486\n",
      "Parameters: {'no_components': 16, 'learning_rate': 0.05, 'item_alpha': 0.001, 'user_alpha': 0.01, 'max_sampled': 15, 'loss': 'warp'}\n",
      "Result: train_precision = 0.28978776931762695, test_precision = 0.0014606156619265676\n",
      "Step 12 of 486\n",
      "Parameters: {'no_components': 16, 'learning_rate': 0.05, 'item_alpha': 0.001, 'user_alpha': 0.01, 'max_sampled': 15, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.2004805952310562, test_precision = 0.0013562857639044523\n",
      "Step 13 of 486\n",
      "Parameters: {'no_components': 16, 'learning_rate': 0.05, 'item_alpha': 0.001, 'user_alpha': 0.1, 'max_sampled': 5, 'loss': 'warp'}\n",
      "Result: train_precision = 0.2941129505634308, test_precision = 0.0013562858803197742\n",
      "Step 14 of 486\n",
      "Parameters: {'no_components': 16, 'learning_rate': 0.05, 'item_alpha': 0.001, 'user_alpha': 0.1, 'max_sampled': 5, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.1388866901397705, test_precision = 0.003964527975767851\n",
      "Step 15 of 486\n",
      "Parameters: {'no_components': 16, 'learning_rate': 0.05, 'item_alpha': 0.001, 'user_alpha': 0.1, 'max_sampled': 10, 'loss': 'warp'}\n",
      "Result: train_precision = 0.2941129505634308, test_precision = 0.0013562858803197742\n",
      "Step 16 of 486\n",
      "Parameters: {'no_components': 16, 'learning_rate': 0.05, 'item_alpha': 0.001, 'user_alpha': 0.1, 'max_sampled': 10, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.1396075338125229, test_precision = 0.003651539096608758\n",
      "Step 17 of 486\n",
      "Parameters: {'no_components': 16, 'learning_rate': 0.05, 'item_alpha': 0.001, 'user_alpha': 0.1, 'max_sampled': 15, 'loss': 'warp'}\n",
      "Result: train_precision = 0.2941129505634308, test_precision = 0.0013562858803197742\n",
      "Step 18 of 486\n",
      "Parameters: {'no_components': 16, 'learning_rate': 0.05, 'item_alpha': 0.001, 'user_alpha': 0.1, 'max_sampled': 15, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.14136964082717896, test_precision = 0.002921231323853135\n",
      "Step 19 of 486\n",
      "Parameters: {'no_components': 16, 'learning_rate': 0.05, 'item_alpha': 0.01, 'user_alpha': 0.001, 'max_sampled': 5, 'loss': 'warp'}\n",
      "Result: train_precision = 0.18862634897232056, test_precision = 0.0007303077727556229\n",
      "Step 20 of 486\n",
      "Parameters: {'no_components': 16, 'learning_rate': 0.05, 'item_alpha': 0.01, 'user_alpha': 0.001, 'max_sampled': 5, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.4385262429714203, test_precision = 0.0014606156619265676\n",
      "Step 21 of 486\n",
      "Parameters: {'no_components': 16, 'learning_rate': 0.05, 'item_alpha': 0.01, 'user_alpha': 0.001, 'max_sampled': 10, 'loss': 'warp'}\n",
      "Result: train_precision = 0.286984384059906, test_precision = 0.0012519562151283026\n",
      "Step 22 of 486\n",
      "Parameters: {'no_components': 16, 'learning_rate': 0.05, 'item_alpha': 0.01, 'user_alpha': 0.001, 'max_sampled': 10, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.4385262429714203, test_precision = 0.0014606156619265676\n",
      "Step 23 of 486\n",
      "Parameters: {'no_components': 16, 'learning_rate': 0.05, 'item_alpha': 0.01, 'user_alpha': 0.001, 'max_sampled': 15, 'loss': 'warp'}\n",
      "Result: train_precision = 0.18678414821624756, test_precision = 0.0007303077727556229\n",
      "Step 24 of 486\n",
      "Parameters: {'no_components': 16, 'learning_rate': 0.05, 'item_alpha': 0.01, 'user_alpha': 0.001, 'max_sampled': 15, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.4385262429714203, test_precision = 0.0014606156619265676\n",
      "Step 25 of 486\n",
      "Parameters: {'no_components': 16, 'learning_rate': 0.05, 'item_alpha': 0.01, 'user_alpha': 0.01, 'max_sampled': 5, 'loss': 'warp'}\n",
      "Result: train_precision = 0.17444933950901031, test_precision = 0.0007303077727556229\n",
      "Step 26 of 486\n",
      "Parameters: {'no_components': 16, 'learning_rate': 0.05, 'item_alpha': 0.01, 'user_alpha': 0.01, 'max_sampled': 5, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.4385262429714203, test_precision = 0.0014606156619265676\n",
      "Step 27 of 486\n",
      "Parameters: {'no_components': 16, 'learning_rate': 0.05, 'item_alpha': 0.01, 'user_alpha': 0.01, 'max_sampled': 10, 'loss': 'warp'}\n",
      "Result: train_precision = 0.2792951762676239, test_precision = 0.0010432967683300376\n",
      "Step 28 of 486\n",
      "Parameters: {'no_components': 16, 'learning_rate': 0.05, 'item_alpha': 0.01, 'user_alpha': 0.01, 'max_sampled': 10, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.4385262429714203, test_precision = 0.0014606156619265676\n",
      "Step 29 of 486\n",
      "Parameters: {'no_components': 16, 'learning_rate': 0.05, 'item_alpha': 0.01, 'user_alpha': 0.01, 'max_sampled': 15, 'loss': 'warp'}\n",
      "Result: train_precision = 0.28394073247909546, test_precision = 0.0013562858803197742\n",
      "Step 30 of 486\n",
      "Parameters: {'no_components': 16, 'learning_rate': 0.05, 'item_alpha': 0.01, 'user_alpha': 0.01, 'max_sampled': 15, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.4385262429714203, test_precision = 0.0014606156619265676\n",
      "Step 31 of 486\n",
      "Parameters: {'no_components': 16, 'learning_rate': 0.05, 'item_alpha': 0.01, 'user_alpha': 0.1, 'max_sampled': 5, 'loss': 'warp'}\n",
      "Result: train_precision = 0.2941129505634308, test_precision = 0.0013562858803197742\n",
      "Step 32 of 486\n",
      "Parameters: {'no_components': 16, 'learning_rate': 0.05, 'item_alpha': 0.01, 'user_alpha': 0.1, 'max_sampled': 5, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.14169003069400787, test_precision = 0.0012519562151283026\n",
      "Step 33 of 486\n",
      "Parameters: {'no_components': 16, 'learning_rate': 0.05, 'item_alpha': 0.01, 'user_alpha': 0.1, 'max_sampled': 10, 'loss': 'warp'}\n",
      "Result: train_precision = 0.2941129505634308, test_precision = 0.0013562858803197742\n",
      "Step 34 of 486\n",
      "Parameters: {'no_components': 16, 'learning_rate': 0.05, 'item_alpha': 0.01, 'user_alpha': 0.1, 'max_sampled': 10, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.14088907837867737, test_precision = 0.0019822639878839254\n",
      "Step 35 of 486\n",
      "Parameters: {'no_components': 16, 'learning_rate': 0.05, 'item_alpha': 0.01, 'user_alpha': 0.1, 'max_sampled': 15, 'loss': 'warp'}\n",
      "Result: train_precision = 0.2941129505634308, test_precision = 0.0013562858803197742\n",
      "Step 36 of 486\n",
      "Parameters: {'no_components': 16, 'learning_rate': 0.05, 'item_alpha': 0.01, 'user_alpha': 0.1, 'max_sampled': 15, 'loss': 'bpr'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: train_precision = 0.17669205367565155, test_precision = 0.0016692748758941889\n",
      "Step 37 of 486\n",
      "Parameters: {'no_components': 16, 'learning_rate': 0.05, 'item_alpha': 0.1, 'user_alpha': 0.001, 'max_sampled': 5, 'loss': 'warp'}\n",
      "Result: train_precision = 0.09443332254886627, test_precision = 0.0010432967683300376\n",
      "Step 38 of 486\n",
      "Parameters: {'no_components': 16, 'learning_rate': 0.05, 'item_alpha': 0.1, 'user_alpha': 0.001, 'max_sampled': 5, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.2041650116443634, test_precision = 0.002086593536660075\n",
      "Step 39 of 486\n",
      "Parameters: {'no_components': 16, 'learning_rate': 0.05, 'item_alpha': 0.1, 'user_alpha': 0.001, 'max_sampled': 10, 'loss': 'warp'}\n",
      "Result: train_precision = 0.22635163366794586, test_precision = 0.0012519562151283026\n",
      "Step 40 of 486\n",
      "Parameters: {'no_components': 16, 'learning_rate': 0.05, 'item_alpha': 0.1, 'user_alpha': 0.001, 'max_sampled': 10, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.20032040774822235, test_precision = 0.001877934206277132\n",
      "Step 41 of 486\n",
      "Parameters: {'no_components': 16, 'learning_rate': 0.05, 'item_alpha': 0.1, 'user_alpha': 0.001, 'max_sampled': 15, 'loss': 'warp'}\n",
      "Result: train_precision = 0.1815779060125351, test_precision = 0.0016692751087248325\n",
      "Step 42 of 486\n",
      "Parameters: {'no_components': 16, 'learning_rate': 0.05, 'item_alpha': 0.1, 'user_alpha': 0.001, 'max_sampled': 15, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.19815780222415924, test_precision = 0.0015649452107027173\n",
      "Step 43 of 486\n",
      "Parameters: {'no_components': 16, 'learning_rate': 0.05, 'item_alpha': 0.1, 'user_alpha': 0.01, 'max_sampled': 5, 'loss': 'warp'}\n",
      "Result: train_precision = 0.09443332254886627, test_precision = 0.0010432967683300376\n",
      "Step 44 of 486\n",
      "Parameters: {'no_components': 16, 'learning_rate': 0.05, 'item_alpha': 0.1, 'user_alpha': 0.01, 'max_sampled': 5, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.20488588511943817, test_precision = 0.0015649452107027173\n",
      "Step 45 of 486\n",
      "Parameters: {'no_components': 16, 'learning_rate': 0.05, 'item_alpha': 0.1, 'user_alpha': 0.01, 'max_sampled': 10, 'loss': 'warp'}\n",
      "Result: train_precision = 0.13944734632968903, test_precision = 0.0010432967683300376\n",
      "Step 46 of 486\n",
      "Parameters: {'no_components': 16, 'learning_rate': 0.05, 'item_alpha': 0.1, 'user_alpha': 0.01, 'max_sampled': 10, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.20168203115463257, test_precision = 0.0005216483841650188\n",
      "Step 47 of 486\n",
      "Parameters: {'no_components': 16, 'learning_rate': 0.05, 'item_alpha': 0.1, 'user_alpha': 0.01, 'max_sampled': 15, 'loss': 'warp'}\n",
      "Result: train_precision = 0.26167404651641846, test_precision = 0.0017736046575009823\n",
      "Step 48 of 486\n",
      "Parameters: {'no_components': 16, 'learning_rate': 0.05, 'item_alpha': 0.1, 'user_alpha': 0.01, 'max_sampled': 15, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.20136165618896484, test_precision = 0.0014606156619265676\n",
      "Step 49 of 486\n",
      "Parameters: {'no_components': 16, 'learning_rate': 0.05, 'item_alpha': 0.1, 'user_alpha': 0.1, 'max_sampled': 5, 'loss': 'warp'}\n",
      "Result: train_precision = 0.2941129505634308, test_precision = 0.0013562858803197742\n",
      "Step 50 of 486\n",
      "Parameters: {'no_components': 16, 'learning_rate': 0.05, 'item_alpha': 0.1, 'user_alpha': 0.1, 'max_sampled': 5, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.20824989676475525, test_precision = 0.0012519562151283026\n",
      "Step 51 of 486\n",
      "Parameters: {'no_components': 16, 'learning_rate': 0.05, 'item_alpha': 0.1, 'user_alpha': 0.1, 'max_sampled': 10, 'loss': 'warp'}\n",
      "Result: train_precision = 0.2941129505634308, test_precision = 0.0013562858803197742\n",
      "Step 52 of 486\n",
      "Parameters: {'no_components': 16, 'learning_rate': 0.05, 'item_alpha': 0.1, 'user_alpha': 0.1, 'max_sampled': 10, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.20824989676475525, test_precision = 0.0012519562151283026\n",
      "Step 53 of 486\n",
      "Parameters: {'no_components': 16, 'learning_rate': 0.05, 'item_alpha': 0.1, 'user_alpha': 0.1, 'max_sampled': 15, 'loss': 'warp'}\n",
      "Result: train_precision = 0.2941129505634308, test_precision = 0.0013562858803197742\n",
      "Step 54 of 486\n",
      "Parameters: {'no_components': 16, 'learning_rate': 0.05, 'item_alpha': 0.1, 'user_alpha': 0.1, 'max_sampled': 15, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.20937126874923706, test_precision = 0.0012519562151283026\n",
      "Step 55 of 486\n",
      "Parameters: {'no_components': 16, 'learning_rate': 0.5, 'item_alpha': 0.001, 'user_alpha': 0.001, 'max_sampled': 5, 'loss': 'warp'}\n",
      "Result: train_precision = 0.06071285903453827, test_precision = 0.000938967103138566\n",
      "Step 56 of 486\n",
      "Parameters: {'no_components': 16, 'learning_rate': 0.5, 'item_alpha': 0.001, 'user_alpha': 0.001, 'max_sampled': 5, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.14537446200847626, test_precision = 0.002921231323853135\n",
      "Step 57 of 486\n",
      "Parameters: {'no_components': 16, 'learning_rate': 0.5, 'item_alpha': 0.001, 'user_alpha': 0.001, 'max_sampled': 10, 'loss': 'warp'}\n",
      "Result: train_precision = 0.06015218794345856, test_precision = 0.0018779343226924539\n",
      "Step 58 of 486\n",
      "Parameters: {'no_components': 16, 'learning_rate': 0.5, 'item_alpha': 0.001, 'user_alpha': 0.001, 'max_sampled': 10, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.14305166900157928, test_precision = 0.0023995828814804554\n",
      "Step 59 of 486\n",
      "Parameters: {'no_components': 16, 'learning_rate': 0.5, 'item_alpha': 0.001, 'user_alpha': 0.001, 'max_sampled': 15, 'loss': 'warp'}\n",
      "Result: train_precision = 0.09154985845088959, test_precision = 0.002086593536660075\n",
      "Step 60 of 486\n",
      "Parameters: {'no_components': 16, 'learning_rate': 0.5, 'item_alpha': 0.001, 'user_alpha': 0.001, 'max_sampled': 15, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.1470564752817154, test_precision = 0.0021909235510975122\n",
      "Step 61 of 486\n",
      "Parameters: {'no_components': 16, 'learning_rate': 0.5, 'item_alpha': 0.001, 'user_alpha': 0.01, 'max_sampled': 5, 'loss': 'warp'}\n",
      "Result: train_precision = 0.07705246657133102, test_precision = 0.002608241979032755\n",
      "Step 62 of 486\n",
      "Parameters: {'no_components': 16, 'learning_rate': 0.5, 'item_alpha': 0.001, 'user_alpha': 0.01, 'max_sampled': 5, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.14209051430225372, test_precision = 0.003025560872629285\n",
      "Step 63 of 486\n",
      "Parameters: {'no_components': 16, 'learning_rate': 0.5, 'item_alpha': 0.001, 'user_alpha': 0.01, 'max_sampled': 10, 'loss': 'warp'}\n",
      "Result: train_precision = 0.05903083458542824, test_precision = 0.0008346374379470944\n",
      "Step 64 of 486\n",
      "Parameters: {'no_components': 16, 'learning_rate': 0.5, 'item_alpha': 0.001, 'user_alpha': 0.01, 'max_sampled': 10, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.14209052920341492, test_precision = 0.0015649452107027173\n",
      "Step 65 of 486\n",
      "Parameters: {'no_components': 16, 'learning_rate': 0.5, 'item_alpha': 0.001, 'user_alpha': 0.01, 'max_sampled': 15, 'loss': 'warp'}\n",
      "Result: train_precision = 0.0870644822716713, test_precision = 0.0013562857639044523\n",
      "Step 66 of 486\n",
      "Parameters: {'no_components': 16, 'learning_rate': 0.5, 'item_alpha': 0.001, 'user_alpha': 0.01, 'max_sampled': 15, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.13920706510543823, test_precision = 0.0014606155455112457\n",
      "Step 67 of 486\n",
      "Parameters: {'no_components': 16, 'learning_rate': 0.5, 'item_alpha': 0.001, 'user_alpha': 0.1, 'max_sampled': 5, 'loss': 'warp'}\n",
      "Result: train_precision = 0.05590708926320076, test_precision = 0.0005216483841650188\n",
      "Step 68 of 486\n",
      "Parameters: {'no_components': 16, 'learning_rate': 0.5, 'item_alpha': 0.001, 'user_alpha': 0.1, 'max_sampled': 5, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.14849822223186493, test_precision = 0.0015649452107027173\n",
      "Step 69 of 486\n",
      "Parameters: {'no_components': 16, 'learning_rate': 0.5, 'item_alpha': 0.001, 'user_alpha': 0.1, 'max_sampled': 10, 'loss': 'warp'}\n",
      "Result: train_precision = 0.10052062571048737, test_precision = 0.0031298904214054346\n",
      "Step 70 of 486\n",
      "Parameters: {'no_components': 16, 'learning_rate': 0.5, 'item_alpha': 0.001, 'user_alpha': 0.1, 'max_sampled': 10, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.14537444710731506, test_precision = 0.0012519562151283026\n",
      "Step 71 of 486\n",
      "Parameters: {'no_components': 16, 'learning_rate': 0.5, 'item_alpha': 0.001, 'user_alpha': 0.1, 'max_sampled': 15, 'loss': 'warp'}\n",
      "Result: train_precision = 0.10164196789264679, test_precision = 0.0023995828814804554\n",
      "Step 72 of 486\n",
      "Parameters: {'no_components': 16, 'learning_rate': 0.5, 'item_alpha': 0.001, 'user_alpha': 0.1, 'max_sampled': 15, 'loss': 'bpr'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: train_precision = 0.1420104205608368, test_precision = 0.0012519562151283026\n",
      "Step 73 of 486\n",
      "Parameters: {'no_components': 16, 'learning_rate': 0.5, 'item_alpha': 0.01, 'user_alpha': 0.001, 'max_sampled': 5, 'loss': 'warp'}\n",
      "Result: train_precision = 0.0793752521276474, test_precision = 0.003755868412554264\n",
      "Step 74 of 486\n",
      "Parameters: {'no_components': 16, 'learning_rate': 0.5, 'item_alpha': 0.01, 'user_alpha': 0.001, 'max_sampled': 5, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.14128956198692322, test_precision = 0.0017736046575009823\n",
      "Step 75 of 486\n",
      "Parameters: {'no_components': 16, 'learning_rate': 0.5, 'item_alpha': 0.01, 'user_alpha': 0.001, 'max_sampled': 10, 'loss': 'warp'}\n",
      "Result: train_precision = 0.07561073452234268, test_precision = 0.0027125715278089046\n",
      "Step 76 of 486\n",
      "Parameters: {'no_components': 16, 'learning_rate': 0.5, 'item_alpha': 0.01, 'user_alpha': 0.001, 'max_sampled': 10, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.14048859477043152, test_precision = 0.0008346374379470944\n",
      "Step 77 of 486\n",
      "Parameters: {'no_components': 16, 'learning_rate': 0.5, 'item_alpha': 0.01, 'user_alpha': 0.001, 'max_sampled': 15, 'loss': 'warp'}\n",
      "Result: train_precision = 0.10580697655677795, test_precision = 0.0029212310910224915\n",
      "Step 78 of 486\n",
      "Parameters: {'no_components': 16, 'learning_rate': 0.5, 'item_alpha': 0.01, 'user_alpha': 0.001, 'max_sampled': 15, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.14481379091739655, test_precision = 0.002086593536660075\n",
      "Step 79 of 486\n",
      "Parameters: {'no_components': 16, 'learning_rate': 0.5, 'item_alpha': 0.01, 'user_alpha': 0.01, 'max_sampled': 5, 'loss': 'warp'}\n",
      "Result: train_precision = 0.07729274779558182, test_precision = 0.0027125715278089046\n",
      "Step 80 of 486\n",
      "Parameters: {'no_components': 16, 'learning_rate': 0.5, 'item_alpha': 0.01, 'user_alpha': 0.01, 'max_sampled': 5, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.2144974321126938, test_precision = 0.0017736046575009823\n",
      "Step 81 of 486\n",
      "Parameters: {'no_components': 16, 'learning_rate': 0.5, 'item_alpha': 0.01, 'user_alpha': 0.01, 'max_sampled': 10, 'loss': 'warp'}\n",
      "Result: train_precision = 0.075931116938591, test_precision = 0.003025560872629285\n",
      "Step 82 of 486\n",
      "Parameters: {'no_components': 16, 'learning_rate': 0.5, 'item_alpha': 0.01, 'user_alpha': 0.01, 'max_sampled': 10, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.21121346950531006, test_precision = 0.0015649452107027173\n",
      "Step 83 of 486\n",
      "Parameters: {'no_components': 16, 'learning_rate': 0.5, 'item_alpha': 0.01, 'user_alpha': 0.01, 'max_sampled': 15, 'loss': 'warp'}\n",
      "Result: train_precision = 0.10516620427370071, test_precision = 0.004590506199747324\n",
      "Step 84 of 486\n",
      "Parameters: {'no_components': 16, 'learning_rate': 0.5, 'item_alpha': 0.01, 'user_alpha': 0.01, 'max_sampled': 15, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.20504605770111084, test_precision = 0.0027125715278089046\n",
      "Step 85 of 486\n",
      "Parameters: {'no_components': 16, 'learning_rate': 0.5, 'item_alpha': 0.01, 'user_alpha': 0.1, 'max_sampled': 5, 'loss': 'warp'}\n",
      "Result: train_precision = 0.06119343265891075, test_precision = 0.002816901309415698\n",
      "Step 86 of 486\n",
      "Parameters: {'no_components': 16, 'learning_rate': 0.5, 'item_alpha': 0.01, 'user_alpha': 0.1, 'max_sampled': 5, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.14753705263137817, test_precision = 0.0017736046575009823\n",
      "Step 87 of 486\n",
      "Parameters: {'no_components': 16, 'learning_rate': 0.5, 'item_alpha': 0.01, 'user_alpha': 0.1, 'max_sampled': 10, 'loss': 'warp'}\n",
      "Result: train_precision = 0.09171005338430405, test_precision = 0.004381846636533737\n",
      "Step 88 of 486\n",
      "Parameters: {'no_components': 16, 'learning_rate': 0.5, 'item_alpha': 0.01, 'user_alpha': 0.1, 'max_sampled': 10, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.1454545557498932, test_precision = 0.002086593536660075\n",
      "Step 89 of 486\n",
      "Parameters: {'no_components': 16, 'learning_rate': 0.5, 'item_alpha': 0.01, 'user_alpha': 0.1, 'max_sampled': 15, 'loss': 'warp'}\n",
      "Result: train_precision = 0.09090909361839294, test_precision = 0.0014606155455112457\n",
      "Step 90 of 486\n",
      "Parameters: {'no_components': 16, 'learning_rate': 0.5, 'item_alpha': 0.01, 'user_alpha': 0.1, 'max_sampled': 15, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.14697636663913727, test_precision = 0.0014606156619265676\n",
      "Step 91 of 486\n",
      "Parameters: {'no_components': 16, 'learning_rate': 0.5, 'item_alpha': 0.1, 'user_alpha': 0.001, 'max_sampled': 5, 'loss': 'warp'}\n",
      "Result: train_precision = 0.15786944329738617, test_precision = 0.0031298904214054346\n",
      "Step 92 of 486\n",
      "Parameters: {'no_components': 16, 'learning_rate': 0.5, 'item_alpha': 0.1, 'user_alpha': 0.001, 'max_sampled': 5, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.15258309245109558, test_precision = 0.0023995828814804554\n",
      "Step 93 of 486\n",
      "Parameters: {'no_components': 16, 'learning_rate': 0.5, 'item_alpha': 0.1, 'user_alpha': 0.001, 'max_sampled': 10, 'loss': 'warp'}\n",
      "Result: train_precision = 0.15883061289787292, test_precision = 0.001877934206277132\n",
      "Step 94 of 486\n",
      "Parameters: {'no_components': 16, 'learning_rate': 0.5, 'item_alpha': 0.1, 'user_alpha': 0.001, 'max_sampled': 10, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.14801762998104095, test_precision = 0.0019822639878839254\n",
      "Step 95 of 486\n",
      "Parameters: {'no_components': 16, 'learning_rate': 0.5, 'item_alpha': 0.1, 'user_alpha': 0.001, 'max_sampled': 15, 'loss': 'warp'}\n",
      "Result: train_precision = 0.15578696131706238, test_precision = 0.003338550217449665\n",
      "Step 96 of 486\n",
      "Parameters: {'no_components': 16, 'learning_rate': 0.5, 'item_alpha': 0.1, 'user_alpha': 0.001, 'max_sampled': 15, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.15859031677246094, test_precision = 0.002086593536660075\n",
      "Step 97 of 486\n",
      "Parameters: {'no_components': 16, 'learning_rate': 0.5, 'item_alpha': 0.1, 'user_alpha': 0.01, 'max_sampled': 5, 'loss': 'warp'}\n",
      "Result: train_precision = 0.15810973942279816, test_precision = 0.0017736046575009823\n",
      "Step 98 of 486\n",
      "Parameters: {'no_components': 16, 'learning_rate': 0.5, 'item_alpha': 0.1, 'user_alpha': 0.01, 'max_sampled': 5, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.2110532820224762, test_precision = 0.0015649452107027173\n",
      "Step 99 of 486\n",
      "Parameters: {'no_components': 16, 'learning_rate': 0.5, 'item_alpha': 0.1, 'user_alpha': 0.01, 'max_sampled': 10, 'loss': 'warp'}\n",
      "Result: train_precision = 0.15698839724063873, test_precision = 0.0018779343226924539\n",
      "Step 100 of 486\n",
      "Parameters: {'no_components': 16, 'learning_rate': 0.5, 'item_alpha': 0.1, 'user_alpha': 0.01, 'max_sampled': 10, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.21129359304904938, test_precision = 0.002086593536660075\n",
      "Step 101 of 486\n",
      "Parameters: {'no_components': 16, 'learning_rate': 0.5, 'item_alpha': 0.1, 'user_alpha': 0.01, 'max_sampled': 15, 'loss': 'warp'}\n",
      "Result: train_precision = 0.15658792853355408, test_precision = 0.002921231323853135\n",
      "Step 102 of 486\n",
      "Parameters: {'no_components': 16, 'learning_rate': 0.5, 'item_alpha': 0.1, 'user_alpha': 0.01, 'max_sampled': 15, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.21129359304904938, test_precision = 0.0016692748758941889\n",
      "Step 103 of 486\n",
      "Parameters: {'no_components': 16, 'learning_rate': 0.5, 'item_alpha': 0.1, 'user_alpha': 0.1, 'max_sampled': 5, 'loss': 'warp'}\n",
      "Result: train_precision = 0.21257510781288147, test_precision = 0.002295253099873662\n",
      "Step 104 of 486\n",
      "Parameters: {'no_components': 16, 'learning_rate': 0.5, 'item_alpha': 0.1, 'user_alpha': 0.1, 'max_sampled': 5, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.21097318828105927, test_precision = 0.0018779343226924539\n",
      "Step 105 of 486\n",
      "Parameters: {'no_components': 16, 'learning_rate': 0.5, 'item_alpha': 0.1, 'user_alpha': 0.1, 'max_sampled': 10, 'loss': 'warp'}\n",
      "Result: train_precision = 0.22442932426929474, test_precision = 0.001877934206277132\n",
      "Step 106 of 486\n",
      "Parameters: {'no_components': 16, 'learning_rate': 0.5, 'item_alpha': 0.1, 'user_alpha': 0.1, 'max_sampled': 10, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.2004805952310562, test_precision = 0.00417318707332015\n",
      "Step 107 of 486\n",
      "Parameters: {'no_components': 16, 'learning_rate': 0.5, 'item_alpha': 0.1, 'user_alpha': 0.1, 'max_sampled': 15, 'loss': 'warp'}\n",
      "Result: train_precision = 0.21513819694519043, test_precision = 0.001877934206277132\n",
      "Step 108 of 486\n",
      "Parameters: {'no_components': 16, 'learning_rate': 0.5, 'item_alpha': 0.1, 'user_alpha': 0.1, 'max_sampled': 15, 'loss': 'bpr'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: train_precision = 0.11317581683397293, test_precision = 0.0023995828814804554\n",
      "Step 109 of 486\n",
      "Parameters: {'no_components': 16, 'learning_rate': 1, 'item_alpha': 0.001, 'user_alpha': 0.001, 'max_sampled': 5, 'loss': 'warp'}\n",
      "Result: train_precision = 0.13504205644130707, test_precision = 0.0023995826486498117\n",
      "Step 110 of 486\n",
      "Parameters: {'no_components': 16, 'learning_rate': 1, 'item_alpha': 0.001, 'user_alpha': 0.001, 'max_sampled': 5, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.13872648775577545, test_precision = 0.0008346374379470944\n",
      "Step 111 of 486\n",
      "Parameters: {'no_components': 16, 'learning_rate': 1, 'item_alpha': 0.001, 'user_alpha': 0.001, 'max_sampled': 10, 'loss': 'warp'}\n",
      "Result: train_precision = 0.10292350500822067, test_precision = 0.003234220203012228\n",
      "Step 112 of 486\n",
      "Parameters: {'no_components': 16, 'learning_rate': 1, 'item_alpha': 0.001, 'user_alpha': 0.001, 'max_sampled': 10, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.15010014176368713, test_precision = 0.0036515388637781143\n",
      "Step 113 of 486\n",
      "Parameters: {'no_components': 16, 'learning_rate': 1, 'item_alpha': 0.001, 'user_alpha': 0.001, 'max_sampled': 15, 'loss': 'warp'}\n",
      "Result: train_precision = 0.06063275784254074, test_precision = 0.0012519562151283026\n",
      "Step 114 of 486\n",
      "Parameters: {'no_components': 16, 'learning_rate': 1, 'item_alpha': 0.001, 'user_alpha': 0.001, 'max_sampled': 15, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.14032840728759766, test_precision = 0.0009389671613462269\n",
      "Step 115 of 486\n",
      "Parameters: {'no_components': 16, 'learning_rate': 1, 'item_alpha': 0.001, 'user_alpha': 0.01, 'max_sampled': 5, 'loss': 'warp'}\n",
      "Result: train_precision = 0.05991189181804657, test_precision = 0.0017736046575009823\n",
      "Step 116 of 486\n",
      "Parameters: {'no_components': 16, 'learning_rate': 1, 'item_alpha': 0.001, 'user_alpha': 0.01, 'max_sampled': 5, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.28634360432624817, test_precision = 0.0019822639878839254\n",
      "Step 117 of 486\n",
      "Parameters: {'no_components': 16, 'learning_rate': 1, 'item_alpha': 0.001, 'user_alpha': 0.01, 'max_sampled': 10, 'loss': 'warp'}\n",
      "Result: train_precision = 0.06167401000857353, test_precision = 0.002608241979032755\n",
      "Step 118 of 486\n",
      "Parameters: {'no_components': 16, 'learning_rate': 1, 'item_alpha': 0.001, 'user_alpha': 0.01, 'max_sampled': 10, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.13896676898002625, test_precision = 0.001147626549936831\n",
      "Step 119 of 486\n",
      "Parameters: {'no_components': 16, 'learning_rate': 1, 'item_alpha': 0.001, 'user_alpha': 0.01, 'max_sampled': 15, 'loss': 'warp'}\n",
      "Result: train_precision = 0.18702442944049835, test_precision = 0.0022952528670430183\n",
      "Step 120 of 486\n",
      "Parameters: {'no_components': 16, 'learning_rate': 1, 'item_alpha': 0.001, 'user_alpha': 0.01, 'max_sampled': 15, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.13744494318962097, test_precision = 0.0013562857639044523\n",
      "Step 121 of 486\n",
      "Parameters: {'no_components': 16, 'learning_rate': 1, 'item_alpha': 0.001, 'user_alpha': 0.1, 'max_sampled': 5, 'loss': 'warp'}\n",
      "Result: train_precision = 0.19655586779117584, test_precision = 0.002086593536660075\n",
      "Step 122 of 486\n",
      "Parameters: {'no_components': 16, 'learning_rate': 1, 'item_alpha': 0.001, 'user_alpha': 0.1, 'max_sampled': 5, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.1645975261926651, test_precision = 0.0012519562151283026\n",
      "Step 123 of 486\n",
      "Parameters: {'no_components': 16, 'learning_rate': 1, 'item_alpha': 0.001, 'user_alpha': 0.1, 'max_sampled': 10, 'loss': 'warp'}\n",
      "Result: train_precision = 0.10420504957437515, test_precision = 0.0028169015422463417\n",
      "Step 124 of 486\n",
      "Parameters: {'no_components': 16, 'learning_rate': 1, 'item_alpha': 0.001, 'user_alpha': 0.1, 'max_sampled': 10, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.14633561670780182, test_precision = 0.0009389671613462269\n",
      "Step 125 of 486\n",
      "Parameters: {'no_components': 16, 'learning_rate': 1, 'item_alpha': 0.001, 'user_alpha': 0.1, 'max_sampled': 15, 'loss': 'warp'}\n",
      "Result: train_precision = 0.1821385771036148, test_precision = 0.003964527975767851\n",
      "Step 126 of 486\n",
      "Parameters: {'no_components': 16, 'learning_rate': 1, 'item_alpha': 0.001, 'user_alpha': 0.1, 'max_sampled': 15, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.13896675407886505, test_precision = 0.0018779343226924539\n",
      "Step 127 of 486\n",
      "Parameters: {'no_components': 16, 'learning_rate': 1, 'item_alpha': 0.01, 'user_alpha': 0.001, 'max_sampled': 5, 'loss': 'warp'}\n",
      "Result: train_precision = 0.08113736659288406, test_precision = 0.0042775166220963\n",
      "Step 128 of 486\n",
      "Parameters: {'no_components': 16, 'learning_rate': 1, 'item_alpha': 0.01, 'user_alpha': 0.001, 'max_sampled': 5, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.1465758979320526, test_precision = 0.0035472093150019646\n",
      "Step 129 of 486\n",
      "Parameters: {'no_components': 16, 'learning_rate': 1, 'item_alpha': 0.01, 'user_alpha': 0.001, 'max_sampled': 10, 'loss': 'warp'}\n",
      "Result: train_precision = 0.18678414821624756, test_precision = 0.004486176650971174\n",
      "Step 130 of 486\n",
      "Parameters: {'no_components': 16, 'learning_rate': 1, 'item_alpha': 0.01, 'user_alpha': 0.001, 'max_sampled': 10, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.1452142745256424, test_precision = 0.0019822639878839254\n",
      "Step 131 of 486\n",
      "Parameters: {'no_components': 16, 'learning_rate': 1, 'item_alpha': 0.01, 'user_alpha': 0.001, 'max_sampled': 15, 'loss': 'warp'}\n",
      "Result: train_precision = 0.22795356810092926, test_precision = 0.0015649452107027173\n",
      "Step 132 of 486\n",
      "Parameters: {'no_components': 16, 'learning_rate': 1, 'item_alpha': 0.01, 'user_alpha': 0.001, 'max_sampled': 15, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.1464957892894745, test_precision = 0.0016692748758941889\n",
      "Step 133 of 486\n",
      "Parameters: {'no_components': 16, 'learning_rate': 1, 'item_alpha': 0.01, 'user_alpha': 0.01, 'max_sampled': 5, 'loss': 'warp'}\n",
      "Result: train_precision = 0.18710452318191528, test_precision = 0.002295253099873662\n",
      "Step 134 of 486\n",
      "Parameters: {'no_components': 16, 'learning_rate': 1, 'item_alpha': 0.01, 'user_alpha': 0.01, 'max_sampled': 5, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.209451362490654, test_precision = 0.0013562857639044523\n",
      "Step 135 of 486\n",
      "Parameters: {'no_components': 16, 'learning_rate': 1, 'item_alpha': 0.01, 'user_alpha': 0.01, 'max_sampled': 10, 'loss': 'warp'}\n",
      "Result: train_precision = 0.18694433569908142, test_precision = 0.0031298904214054346\n",
      "Step 136 of 486\n",
      "Parameters: {'no_components': 16, 'learning_rate': 1, 'item_alpha': 0.01, 'user_alpha': 0.01, 'max_sampled': 10, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.21129359304904938, test_precision = 0.0012519562151283026\n",
      "Step 137 of 486\n",
      "Parameters: {'no_components': 16, 'learning_rate': 1, 'item_alpha': 0.01, 'user_alpha': 0.01, 'max_sampled': 15, 'loss': 'warp'}\n",
      "Result: train_precision = 0.22531035542488098, test_precision = 0.0008346374379470944\n",
      "Step 138 of 486\n",
      "Parameters: {'no_components': 16, 'learning_rate': 1, 'item_alpha': 0.01, 'user_alpha': 0.01, 'max_sampled': 15, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.2044052928686142, test_precision = 0.0019822639878839254\n",
      "Step 139 of 486\n",
      "Parameters: {'no_components': 16, 'learning_rate': 1, 'item_alpha': 0.01, 'user_alpha': 0.1, 'max_sampled': 5, 'loss': 'warp'}\n",
      "Result: train_precision = 0.20400480926036835, test_precision = 0.001877934206277132\n",
      "Step 140 of 486\n",
      "Parameters: {'no_components': 16, 'learning_rate': 1, 'item_alpha': 0.01, 'user_alpha': 0.1, 'max_sampled': 5, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.15442532300949097, test_precision = 0.0018779343226924539\n",
      "Step 141 of 486\n",
      "Parameters: {'no_components': 16, 'learning_rate': 1, 'item_alpha': 0.01, 'user_alpha': 0.1, 'max_sampled': 10, 'loss': 'warp'}\n",
      "Result: train_precision = 0.1728474348783493, test_precision = 0.0016692751087248325\n",
      "Step 142 of 486\n",
      "Parameters: {'no_components': 16, 'learning_rate': 1, 'item_alpha': 0.01, 'user_alpha': 0.1, 'max_sampled': 10, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.15762917697429657, test_precision = 0.0021909235510975122\n",
      "Step 143 of 486\n",
      "Parameters: {'no_components': 16, 'learning_rate': 1, 'item_alpha': 0.01, 'user_alpha': 0.1, 'max_sampled': 15, 'loss': 'warp'}\n",
      "Result: train_precision = 0.34633561968803406, test_precision = 0.0009389671613462269\n",
      "Step 144 of 486\n",
      "Parameters: {'no_components': 16, 'learning_rate': 1, 'item_alpha': 0.01, 'user_alpha': 0.1, 'max_sampled': 15, 'loss': 'bpr'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: train_precision = 0.15394474565982819, test_precision = 0.0023995828814804554\n",
      "Step 145 of 486\n",
      "Parameters: {'no_components': 16, 'learning_rate': 1, 'item_alpha': 0.1, 'user_alpha': 0.001, 'max_sampled': 5, 'loss': 'warp'}\n",
      "Result: train_precision = 0.15778936445713043, test_precision = 0.002086593536660075\n",
      "Step 146 of 486\n",
      "Parameters: {'no_components': 16, 'learning_rate': 1, 'item_alpha': 0.1, 'user_alpha': 0.001, 'max_sampled': 5, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.15074089169502258, test_precision = 0.0018779343226924539\n",
      "Step 147 of 486\n",
      "Parameters: {'no_components': 16, 'learning_rate': 1, 'item_alpha': 0.1, 'user_alpha': 0.001, 'max_sampled': 10, 'loss': 'warp'}\n",
      "Result: train_precision = 0.16331599652767181, test_precision = 0.003025560872629285\n",
      "Step 148 of 486\n",
      "Parameters: {'no_components': 16, 'learning_rate': 1, 'item_alpha': 0.1, 'user_alpha': 0.001, 'max_sampled': 10, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.18646377325057983, test_precision = 0.0014606156619265676\n",
      "Step 149 of 486\n",
      "Parameters: {'no_components': 16, 'learning_rate': 1, 'item_alpha': 0.1, 'user_alpha': 0.001, 'max_sampled': 15, 'loss': 'warp'}\n",
      "Result: train_precision = 0.16411694884300232, test_precision = 0.0021909235510975122\n",
      "Step 150 of 486\n",
      "Parameters: {'no_components': 16, 'learning_rate': 1, 'item_alpha': 0.1, 'user_alpha': 0.001, 'max_sampled': 15, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.151862233877182, test_precision = 0.003025560872629285\n",
      "Step 151 of 486\n",
      "Parameters: {'no_components': 16, 'learning_rate': 1, 'item_alpha': 0.1, 'user_alpha': 0.01, 'max_sampled': 5, 'loss': 'warp'}\n",
      "Result: train_precision = 0.1603524386882782, test_precision = 0.002086593536660075\n",
      "Step 152 of 486\n",
      "Parameters: {'no_components': 16, 'learning_rate': 1, 'item_alpha': 0.1, 'user_alpha': 0.01, 'max_sampled': 5, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.21489788591861725, test_precision = 0.001147626549936831\n",
      "Step 153 of 486\n",
      "Parameters: {'no_components': 16, 'learning_rate': 1, 'item_alpha': 0.1, 'user_alpha': 0.01, 'max_sampled': 10, 'loss': 'warp'}\n",
      "Result: train_precision = 0.21377655863761902, test_precision = 0.002295253099873662\n",
      "Step 154 of 486\n",
      "Parameters: {'no_components': 16, 'learning_rate': 1, 'item_alpha': 0.1, 'user_alpha': 0.01, 'max_sampled': 10, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.20512618124485016, test_precision = 0.000938967103138566\n",
      "Step 155 of 486\n",
      "Parameters: {'no_components': 16, 'learning_rate': 1, 'item_alpha': 0.1, 'user_alpha': 0.01, 'max_sampled': 15, 'loss': 'warp'}\n",
      "Result: train_precision = 0.21561875939369202, test_precision = 0.002086593536660075\n",
      "Step 156 of 486\n",
      "Parameters: {'no_components': 16, 'learning_rate': 1, 'item_alpha': 0.1, 'user_alpha': 0.01, 'max_sampled': 15, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.20264317095279694, test_precision = 0.0013562858803197742\n",
      "Step 157 of 486\n",
      "Parameters: {'no_components': 16, 'learning_rate': 1, 'item_alpha': 0.1, 'user_alpha': 0.1, 'max_sampled': 5, 'loss': 'warp'}\n",
      "Result: train_precision = 0.2084100991487503, test_precision = 0.001877934206277132\n",
      "Step 158 of 486\n",
      "Parameters: {'no_components': 16, 'learning_rate': 1, 'item_alpha': 0.1, 'user_alpha': 0.1, 'max_sampled': 5, 'loss': 'bpr'}\n",
      "Error ocurred, skipping prameter\n",
      "Step 159 of 486\n",
      "Parameters: {'no_components': 16, 'learning_rate': 1, 'item_alpha': 0.1, 'user_alpha': 0.1, 'max_sampled': 10, 'loss': 'warp'}\n",
      "Result: train_precision = 0.21097318828105927, test_precision = 0.001877934206277132\n",
      "Step 160 of 486\n",
      "Parameters: {'no_components': 16, 'learning_rate': 1, 'item_alpha': 0.1, 'user_alpha': 0.1, 'max_sampled': 10, 'loss': 'bpr'}\n",
      "Error ocurred, skipping prameter\n",
      "Step 161 of 486\n",
      "Parameters: {'no_components': 16, 'learning_rate': 1, 'item_alpha': 0.1, 'user_alpha': 0.1, 'max_sampled': 15, 'loss': 'warp'}\n",
      "Result: train_precision = 0.2689628005027771, test_precision = 0.0035472093150019646\n",
      "Step 162 of 486\n",
      "Parameters: {'no_components': 16, 'learning_rate': 1, 'item_alpha': 0.1, 'user_alpha': 0.1, 'max_sampled': 15, 'loss': 'bpr'}\n",
      "Error ocurred, skipping prameter\n",
      "Step 163 of 486\n",
      "Parameters: {'no_components': 40, 'learning_rate': 0.05, 'item_alpha': 0.001, 'user_alpha': 0.001, 'max_sampled': 5, 'loss': 'warp'}\n",
      "Result: train_precision = 0.27921509742736816, test_precision = 0.0027125717606395483\n",
      "Step 164 of 486\n",
      "Parameters: {'no_components': 40, 'learning_rate': 0.05, 'item_alpha': 0.001, 'user_alpha': 0.001, 'max_sampled': 5, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.3799760043621063, test_precision = 0.001147626549936831\n",
      "Step 165 of 486\n",
      "Parameters: {'no_components': 40, 'learning_rate': 0.05, 'item_alpha': 0.001, 'user_alpha': 0.001, 'max_sampled': 10, 'loss': 'warp'}\n",
      "Result: train_precision = 0.2877853810787201, test_precision = 0.002608241979032755\n",
      "Step 166 of 486\n",
      "Parameters: {'no_components': 40, 'learning_rate': 0.05, 'item_alpha': 0.001, 'user_alpha': 0.001, 'max_sampled': 10, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.3649980127811432, test_precision = 0.0012519562151283026\n",
      "Step 167 of 486\n",
      "Parameters: {'no_components': 40, 'learning_rate': 0.05, 'item_alpha': 0.001, 'user_alpha': 0.001, 'max_sampled': 15, 'loss': 'warp'}\n",
      "Result: train_precision = 0.285142183303833, test_precision = 0.001877934206277132\n",
      "Step 168 of 486\n",
      "Parameters: {'no_components': 40, 'learning_rate': 0.05, 'item_alpha': 0.001, 'user_alpha': 0.001, 'max_sampled': 15, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.40208253264427185, test_precision = 0.001147626549936831\n",
      "Step 169 of 486\n",
      "Parameters: {'no_components': 40, 'learning_rate': 0.05, 'item_alpha': 0.001, 'user_alpha': 0.01, 'max_sampled': 5, 'loss': 'warp'}\n",
      "Result: train_precision = 0.28602322936058044, test_precision = 0.0013562858803197742\n",
      "Step 170 of 486\n",
      "Parameters: {'no_components': 40, 'learning_rate': 0.05, 'item_alpha': 0.001, 'user_alpha': 0.01, 'max_sampled': 5, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.19943934679031372, test_precision = 0.0019822639878839254\n",
      "Step 171 of 486\n",
      "Parameters: {'no_components': 40, 'learning_rate': 0.05, 'item_alpha': 0.001, 'user_alpha': 0.01, 'max_sampled': 10, 'loss': 'warp'}\n",
      "Result: train_precision = 0.2930717170238495, test_precision = 0.0014606156619265676\n",
      "Step 172 of 486\n",
      "Parameters: {'no_components': 40, 'learning_rate': 0.05, 'item_alpha': 0.001, 'user_alpha': 0.01, 'max_sampled': 10, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.200961172580719, test_precision = 0.0028169015422463417\n",
      "Step 173 of 486\n",
      "Parameters: {'no_components': 40, 'learning_rate': 0.05, 'item_alpha': 0.001, 'user_alpha': 0.01, 'max_sampled': 15, 'loss': 'warp'}\n",
      "Result: train_precision = 0.2909892201423645, test_precision = 0.0013562858803197742\n",
      "Step 174 of 486\n",
      "Parameters: {'no_components': 40, 'learning_rate': 0.05, 'item_alpha': 0.001, 'user_alpha': 0.01, 'max_sampled': 15, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.2020024210214615, test_precision = 0.0018779343226924539\n",
      "Step 175 of 486\n",
      "Parameters: {'no_components': 40, 'learning_rate': 0.05, 'item_alpha': 0.001, 'user_alpha': 0.1, 'max_sampled': 5, 'loss': 'warp'}\n",
      "Result: train_precision = 0.2933119833469391, test_precision = 0.0013562858803197742\n",
      "Step 176 of 486\n",
      "Parameters: {'no_components': 40, 'learning_rate': 0.05, 'item_alpha': 0.001, 'user_alpha': 0.1, 'max_sampled': 5, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.1407288908958435, test_precision = 0.001147626549936831\n",
      "Step 177 of 486\n",
      "Parameters: {'no_components': 40, 'learning_rate': 0.05, 'item_alpha': 0.001, 'user_alpha': 0.1, 'max_sampled': 10, 'loss': 'warp'}\n",
      "Result: train_precision = 0.26135364174842834, test_precision = 0.001147626549936831\n",
      "Step 178 of 486\n",
      "Parameters: {'no_components': 40, 'learning_rate': 0.05, 'item_alpha': 0.001, 'user_alpha': 0.1, 'max_sampled': 10, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.14024829864501953, test_precision = 0.003964527975767851\n",
      "Step 179 of 486\n",
      "Parameters: {'no_components': 40, 'learning_rate': 0.05, 'item_alpha': 0.001, 'user_alpha': 0.1, 'max_sampled': 15, 'loss': 'warp'}\n",
      "Result: train_precision = 0.2941129505634308, test_precision = 0.0013562858803197742\n",
      "Step 180 of 486\n",
      "Parameters: {'no_components': 40, 'learning_rate': 0.05, 'item_alpha': 0.001, 'user_alpha': 0.1, 'max_sampled': 15, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.13888666033744812, test_precision = 0.0035472093150019646\n",
      "Step 181 of 486\n",
      "Parameters: {'no_components': 40, 'learning_rate': 0.05, 'item_alpha': 0.01, 'user_alpha': 0.001, 'max_sampled': 5, 'loss': 'warp'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: train_precision = 0.2877052426338196, test_precision = 0.0012519562151283026\n",
      "Step 182 of 486\n",
      "Parameters: {'no_components': 40, 'learning_rate': 0.05, 'item_alpha': 0.01, 'user_alpha': 0.001, 'max_sampled': 5, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.39223068952560425, test_precision = 0.0012519562151283026\n",
      "Step 183 of 486\n",
      "Parameters: {'no_components': 40, 'learning_rate': 0.05, 'item_alpha': 0.01, 'user_alpha': 0.001, 'max_sampled': 10, 'loss': 'warp'}\n",
      "Result: train_precision = 0.2905086278915405, test_precision = 0.0013562858803197742\n",
      "Step 184 of 486\n",
      "Parameters: {'no_components': 40, 'learning_rate': 0.05, 'item_alpha': 0.01, 'user_alpha': 0.001, 'max_sampled': 10, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.39014819264411926, test_precision = 0.0012519562151283026\n",
      "Step 185 of 486\n",
      "Parameters: {'no_components': 40, 'learning_rate': 0.05, 'item_alpha': 0.01, 'user_alpha': 0.001, 'max_sampled': 15, 'loss': 'warp'}\n",
      "Result: train_precision = 0.2883460521697998, test_precision = 0.0012519562151283026\n",
      "Step 186 of 486\n",
      "Parameters: {'no_components': 40, 'learning_rate': 0.05, 'item_alpha': 0.01, 'user_alpha': 0.001, 'max_sampled': 15, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.38958752155303955, test_precision = 0.001877934206277132\n",
      "Step 187 of 486\n",
      "Parameters: {'no_components': 40, 'learning_rate': 0.05, 'item_alpha': 0.01, 'user_alpha': 0.01, 'max_sampled': 5, 'loss': 'warp'}\n",
      "Result: train_precision = 0.29379257559776306, test_precision = 0.0013562858803197742\n",
      "Step 188 of 486\n",
      "Parameters: {'no_components': 40, 'learning_rate': 0.05, 'item_alpha': 0.01, 'user_alpha': 0.01, 'max_sampled': 5, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.4378053545951843, test_precision = 0.0014606156619265676\n",
      "Step 189 of 486\n",
      "Parameters: {'no_components': 40, 'learning_rate': 0.05, 'item_alpha': 0.01, 'user_alpha': 0.01, 'max_sampled': 10, 'loss': 'warp'}\n",
      "Result: train_precision = 0.2941129505634308, test_precision = 0.0013562858803197742\n",
      "Step 190 of 486\n",
      "Parameters: {'no_components': 40, 'learning_rate': 0.05, 'item_alpha': 0.01, 'user_alpha': 0.01, 'max_sampled': 10, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.4385262429714203, test_precision = 0.0014606156619265676\n",
      "Step 191 of 486\n",
      "Parameters: {'no_components': 40, 'learning_rate': 0.05, 'item_alpha': 0.01, 'user_alpha': 0.01, 'max_sampled': 15, 'loss': 'warp'}\n",
      "Result: train_precision = 0.2941129505634308, test_precision = 0.0013562858803197742\n",
      "Step 192 of 486\n",
      "Parameters: {'no_components': 40, 'learning_rate': 0.05, 'item_alpha': 0.01, 'user_alpha': 0.01, 'max_sampled': 15, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.3538646697998047, test_precision = 0.0019822639878839254\n",
      "Step 193 of 486\n",
      "Parameters: {'no_components': 40, 'learning_rate': 0.05, 'item_alpha': 0.01, 'user_alpha': 0.1, 'max_sampled': 5, 'loss': 'warp'}\n",
      "Result: train_precision = 0.2941129505634308, test_precision = 0.0013562858803197742\n",
      "Step 194 of 486\n",
      "Parameters: {'no_components': 40, 'learning_rate': 0.05, 'item_alpha': 0.01, 'user_alpha': 0.1, 'max_sampled': 5, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.14112935960292816, test_precision = 0.0023995828814804554\n",
      "Step 195 of 486\n",
      "Parameters: {'no_components': 40, 'learning_rate': 0.05, 'item_alpha': 0.01, 'user_alpha': 0.1, 'max_sampled': 10, 'loss': 'warp'}\n",
      "Result: train_precision = 0.2941129505634308, test_precision = 0.0013562858803197742\n",
      "Step 196 of 486\n",
      "Parameters: {'no_components': 40, 'learning_rate': 0.05, 'item_alpha': 0.01, 'user_alpha': 0.1, 'max_sampled': 10, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.13864637911319733, test_precision = 0.0017736046575009823\n",
      "Step 197 of 486\n",
      "Parameters: {'no_components': 40, 'learning_rate': 0.05, 'item_alpha': 0.01, 'user_alpha': 0.1, 'max_sampled': 15, 'loss': 'warp'}\n",
      "Result: train_precision = 0.2941129505634308, test_precision = 0.0013562858803197742\n",
      "Step 198 of 486\n",
      "Parameters: {'no_components': 40, 'learning_rate': 0.05, 'item_alpha': 0.01, 'user_alpha': 0.1, 'max_sampled': 15, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.14225070178508759, test_precision = 0.001877934206277132\n",
      "Step 199 of 486\n",
      "Parameters: {'no_components': 40, 'learning_rate': 0.05, 'item_alpha': 0.1, 'user_alpha': 0.001, 'max_sampled': 5, 'loss': 'warp'}\n",
      "Result: train_precision = 0.23171807825565338, test_precision = 0.0013562857639044523\n",
      "Step 200 of 486\n",
      "Parameters: {'no_components': 40, 'learning_rate': 0.05, 'item_alpha': 0.1, 'user_alpha': 0.001, 'max_sampled': 5, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.19519424438476562, test_precision = 0.002608241979032755\n",
      "Step 201 of 486\n",
      "Parameters: {'no_components': 40, 'learning_rate': 0.05, 'item_alpha': 0.1, 'user_alpha': 0.001, 'max_sampled': 10, 'loss': 'warp'}\n",
      "Result: train_precision = 0.15050062537193298, test_precision = 0.0015649452107027173\n",
      "Step 202 of 486\n",
      "Parameters: {'no_components': 40, 'learning_rate': 0.05, 'item_alpha': 0.1, 'user_alpha': 0.001, 'max_sampled': 10, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.2068082094192505, test_precision = 0.0015649452107027173\n",
      "Step 203 of 486\n",
      "Parameters: {'no_components': 40, 'learning_rate': 0.05, 'item_alpha': 0.1, 'user_alpha': 0.001, 'max_sampled': 15, 'loss': 'warp'}\n",
      "Result: train_precision = 0.14745695888996124, test_precision = 0.0007303077727556229\n",
      "Step 204 of 486\n",
      "Parameters: {'no_components': 40, 'learning_rate': 0.05, 'item_alpha': 0.1, 'user_alpha': 0.001, 'max_sampled': 15, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.17741291224956512, test_precision = 0.0019822639878839254\n",
      "Step 205 of 486\n",
      "Parameters: {'no_components': 40, 'learning_rate': 0.05, 'item_alpha': 0.1, 'user_alpha': 0.01, 'max_sampled': 5, 'loss': 'warp'}\n",
      "Result: train_precision = 0.2941129505634308, test_precision = 0.0013562858803197742\n",
      "Step 206 of 486\n",
      "Parameters: {'no_components': 40, 'learning_rate': 0.05, 'item_alpha': 0.1, 'user_alpha': 0.01, 'max_sampled': 5, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.20136165618896484, test_precision = 0.0014606156619265676\n",
      "Step 207 of 486\n",
      "Parameters: {'no_components': 40, 'learning_rate': 0.05, 'item_alpha': 0.1, 'user_alpha': 0.01, 'max_sampled': 10, 'loss': 'warp'}\n",
      "Result: train_precision = 0.09443332254886627, test_precision = 0.0010432967683300376\n",
      "Step 208 of 486\n",
      "Parameters: {'no_components': 40, 'learning_rate': 0.05, 'item_alpha': 0.1, 'user_alpha': 0.01, 'max_sampled': 10, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.20136165618896484, test_precision = 0.0014606156619265676\n",
      "Step 209 of 486\n",
      "Parameters: {'no_components': 40, 'learning_rate': 0.05, 'item_alpha': 0.1, 'user_alpha': 0.01, 'max_sampled': 15, 'loss': 'warp'}\n",
      "Result: train_precision = 0.1874249130487442, test_precision = 0.007720396388322115\n",
      "Step 210 of 486\n",
      "Parameters: {'no_components': 40, 'learning_rate': 0.05, 'item_alpha': 0.1, 'user_alpha': 0.01, 'max_sampled': 15, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.21810175478458405, test_precision = 0.005112154874950647\n",
      "Step 211 of 486\n",
      "Parameters: {'no_components': 40, 'learning_rate': 0.05, 'item_alpha': 0.1, 'user_alpha': 0.1, 'max_sampled': 5, 'loss': 'warp'}\n",
      "Result: train_precision = 0.2941129505634308, test_precision = 0.0013562858803197742\n",
      "Step 212 of 486\n",
      "Parameters: {'no_components': 40, 'learning_rate': 0.05, 'item_alpha': 0.1, 'user_alpha': 0.1, 'max_sampled': 5, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.21097318828105927, test_precision = 0.0016692751087248325\n",
      "Step 213 of 486\n",
      "Parameters: {'no_components': 40, 'learning_rate': 0.05, 'item_alpha': 0.1, 'user_alpha': 0.1, 'max_sampled': 10, 'loss': 'warp'}\n",
      "Result: train_precision = 0.2941129505634308, test_precision = 0.0013562858803197742\n",
      "Step 214 of 486\n",
      "Parameters: {'no_components': 40, 'learning_rate': 0.05, 'item_alpha': 0.1, 'user_alpha': 0.1, 'max_sampled': 10, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.21097318828105927, test_precision = 0.0016692751087248325\n",
      "Step 215 of 486\n",
      "Parameters: {'no_components': 40, 'learning_rate': 0.05, 'item_alpha': 0.1, 'user_alpha': 0.1, 'max_sampled': 15, 'loss': 'warp'}\n",
      "Result: train_precision = 0.2941129505634308, test_precision = 0.0013562858803197742\n",
      "Step 216 of 486\n",
      "Parameters: {'no_components': 40, 'learning_rate': 0.05, 'item_alpha': 0.1, 'user_alpha': 0.1, 'max_sampled': 15, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.21097318828105927, test_precision = 0.0016692751087248325\n",
      "Step 217 of 486\n",
      "Parameters: {'no_components': 40, 'learning_rate': 0.5, 'item_alpha': 0.001, 'user_alpha': 0.001, 'max_sampled': 5, 'loss': 'warp'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: train_precision = 0.07761313766241074, test_precision = 0.0029212310910224915\n",
      "Step 218 of 486\n",
      "Parameters: {'no_components': 40, 'learning_rate': 0.5, 'item_alpha': 0.001, 'user_alpha': 0.001, 'max_sampled': 5, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.13784542679786682, test_precision = 0.002921231323853135\n",
      "Step 219 of 486\n",
      "Parameters: {'no_components': 40, 'learning_rate': 0.5, 'item_alpha': 0.001, 'user_alpha': 0.001, 'max_sampled': 10, 'loss': 'warp'}\n",
      "Result: train_precision = 0.1173408105969429, test_precision = 0.0035472093150019646\n",
      "Step 220 of 486\n",
      "Parameters: {'no_components': 40, 'learning_rate': 0.5, 'item_alpha': 0.001, 'user_alpha': 0.001, 'max_sampled': 10, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.1425710916519165, test_precision = 0.0017736046575009823\n",
      "Step 221 of 486\n",
      "Parameters: {'no_components': 40, 'learning_rate': 0.5, 'item_alpha': 0.001, 'user_alpha': 0.001, 'max_sampled': 15, 'loss': 'warp'}\n",
      "Result: train_precision = 0.1054064929485321, test_precision = 0.003025560872629285\n",
      "Step 222 of 486\n",
      "Parameters: {'no_components': 40, 'learning_rate': 0.5, 'item_alpha': 0.001, 'user_alpha': 0.001, 'max_sampled': 15, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.14673610031604767, test_precision = 0.0035472093150019646\n",
      "Step 223 of 486\n",
      "Parameters: {'no_components': 40, 'learning_rate': 0.5, 'item_alpha': 0.001, 'user_alpha': 0.01, 'max_sampled': 5, 'loss': 'warp'}\n",
      "Result: train_precision = 0.07553064078092575, test_precision = 0.002608241979032755\n",
      "Step 224 of 486\n",
      "Parameters: {'no_components': 40, 'learning_rate': 0.5, 'item_alpha': 0.001, 'user_alpha': 0.01, 'max_sampled': 5, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.1423308104276657, test_precision = 0.002608241979032755\n",
      "Step 225 of 486\n",
      "Parameters: {'no_components': 40, 'learning_rate': 0.5, 'item_alpha': 0.001, 'user_alpha': 0.01, 'max_sampled': 10, 'loss': 'warp'}\n",
      "Result: train_precision = 0.10524629056453705, test_precision = 0.00511215440928936\n",
      "Step 226 of 486\n",
      "Parameters: {'no_components': 40, 'learning_rate': 0.5, 'item_alpha': 0.001, 'user_alpha': 0.01, 'max_sampled': 10, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.14225070178508759, test_precision = 0.0016692748758941889\n",
      "Step 227 of 486\n",
      "Parameters: {'no_components': 40, 'learning_rate': 0.5, 'item_alpha': 0.001, 'user_alpha': 0.01, 'max_sampled': 15, 'loss': 'warp'}\n",
      "Result: train_precision = 0.10284340381622314, test_precision = 0.003442879766225815\n",
      "Step 228 of 486\n",
      "Parameters: {'no_components': 40, 'learning_rate': 0.5, 'item_alpha': 0.001, 'user_alpha': 0.01, 'max_sampled': 15, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.13848617672920227, test_precision = 0.0023995826486498117\n",
      "Step 229 of 486\n",
      "Parameters: {'no_components': 40, 'learning_rate': 0.5, 'item_alpha': 0.001, 'user_alpha': 0.1, 'max_sampled': 5, 'loss': 'warp'}\n",
      "Result: train_precision = 0.07769323140382767, test_precision = 0.0021909233182668686\n",
      "Step 230 of 486\n",
      "Parameters: {'no_components': 40, 'learning_rate': 0.5, 'item_alpha': 0.001, 'user_alpha': 0.1, 'max_sampled': 5, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.1423308104276657, test_precision = 0.0006259781075641513\n",
      "Step 231 of 486\n",
      "Parameters: {'no_components': 40, 'learning_rate': 0.5, 'item_alpha': 0.001, 'user_alpha': 0.1, 'max_sampled': 10, 'loss': 'warp'}\n",
      "Result: train_precision = 0.07360833138227463, test_precision = 0.002295253099873662\n",
      "Step 232 of 486\n",
      "Parameters: {'no_components': 40, 'learning_rate': 0.5, 'item_alpha': 0.001, 'user_alpha': 0.1, 'max_sampled': 10, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.14905887842178345, test_precision = 0.0017736046575009823\n",
      "Step 233 of 486\n",
      "Parameters: {'no_components': 40, 'learning_rate': 0.5, 'item_alpha': 0.001, 'user_alpha': 0.1, 'max_sampled': 15, 'loss': 'warp'}\n",
      "Result: train_precision = 0.194313183426857, test_precision = 0.0031298904214054346\n",
      "Step 234 of 486\n",
      "Parameters: {'no_components': 40, 'learning_rate': 0.5, 'item_alpha': 0.001, 'user_alpha': 0.1, 'max_sampled': 15, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.1502603143453598, test_precision = 0.002086593536660075\n",
      "Step 235 of 486\n",
      "Parameters: {'no_components': 40, 'learning_rate': 0.5, 'item_alpha': 0.01, 'user_alpha': 0.001, 'max_sampled': 5, 'loss': 'warp'}\n",
      "Result: train_precision = 0.07384861260652542, test_precision = 0.0031298904214054346\n",
      "Step 236 of 486\n",
      "Parameters: {'no_components': 40, 'learning_rate': 0.5, 'item_alpha': 0.01, 'user_alpha': 0.001, 'max_sampled': 5, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.1465758979320526, test_precision = 0.0037558686453849077\n",
      "Step 237 of 486\n",
      "Parameters: {'no_components': 40, 'learning_rate': 0.5, 'item_alpha': 0.01, 'user_alpha': 0.001, 'max_sampled': 10, 'loss': 'warp'}\n",
      "Result: train_precision = 0.07569082826375961, test_precision = 0.0031298904214054346\n",
      "Step 238 of 486\n",
      "Parameters: {'no_components': 40, 'learning_rate': 0.5, 'item_alpha': 0.01, 'user_alpha': 0.001, 'max_sampled': 10, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.14225070178508759, test_precision = 0.0015649452107027173\n",
      "Step 239 of 486\n",
      "Parameters: {'no_components': 40, 'learning_rate': 0.5, 'item_alpha': 0.01, 'user_alpha': 0.001, 'max_sampled': 15, 'loss': 'warp'}\n",
      "Result: train_precision = 0.18990789353847504, test_precision = 0.0015649452107027173\n",
      "Step 240 of 486\n",
      "Parameters: {'no_components': 40, 'learning_rate': 0.5, 'item_alpha': 0.01, 'user_alpha': 0.001, 'max_sampled': 15, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.14433321356773376, test_precision = 0.002608241979032755\n",
      "Step 241 of 486\n",
      "Parameters: {'no_components': 40, 'learning_rate': 0.5, 'item_alpha': 0.01, 'user_alpha': 0.01, 'max_sampled': 5, 'loss': 'warp'}\n",
      "Result: train_precision = 0.07929515838623047, test_precision = 0.004590506199747324\n",
      "Step 242 of 486\n",
      "Parameters: {'no_components': 40, 'learning_rate': 0.5, 'item_alpha': 0.01, 'user_alpha': 0.01, 'max_sampled': 5, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.1449739784002304, test_precision = 0.0021909233182668686\n",
      "Step 243 of 486\n",
      "Parameters: {'no_components': 40, 'learning_rate': 0.5, 'item_alpha': 0.01, 'user_alpha': 0.01, 'max_sampled': 10, 'loss': 'warp'}\n",
      "Result: train_precision = 0.07745294272899628, test_precision = 0.003964527975767851\n",
      "Step 244 of 486\n",
      "Parameters: {'no_components': 40, 'learning_rate': 0.5, 'item_alpha': 0.01, 'user_alpha': 0.01, 'max_sampled': 10, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.14937926828861237, test_precision = 0.002295253099873662\n",
      "Step 245 of 486\n",
      "Parameters: {'no_components': 40, 'learning_rate': 0.5, 'item_alpha': 0.01, 'user_alpha': 0.01, 'max_sampled': 15, 'loss': 'warp'}\n",
      "Result: train_precision = 0.08329995721578598, test_precision = 0.0023995828814804554\n",
      "Step 246 of 486\n",
      "Parameters: {'no_components': 40, 'learning_rate': 0.5, 'item_alpha': 0.01, 'user_alpha': 0.01, 'max_sampled': 15, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.14633561670780182, test_precision = 0.004590506199747324\n",
      "Step 247 of 486\n",
      "Parameters: {'no_components': 40, 'learning_rate': 0.5, 'item_alpha': 0.01, 'user_alpha': 0.1, 'max_sampled': 5, 'loss': 'warp'}\n",
      "Result: train_precision = 0.0785742923617363, test_precision = 0.002921231323853135\n",
      "Step 248 of 486\n",
      "Parameters: {'no_components': 40, 'learning_rate': 0.5, 'item_alpha': 0.01, 'user_alpha': 0.1, 'max_sampled': 5, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.14809772372245789, test_precision = 0.0027125715278089046\n",
      "Step 249 of 486\n",
      "Parameters: {'no_components': 40, 'learning_rate': 0.5, 'item_alpha': 0.01, 'user_alpha': 0.1, 'max_sampled': 10, 'loss': 'warp'}\n",
      "Result: train_precision = 0.07136564701795578, test_precision = 0.002295253099873662\n",
      "Step 250 of 486\n",
      "Parameters: {'no_components': 40, 'learning_rate': 0.5, 'item_alpha': 0.01, 'user_alpha': 0.1, 'max_sampled': 10, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.15234282612800598, test_precision = 0.002295253099873662\n",
      "Step 251 of 486\n",
      "Parameters: {'no_components': 40, 'learning_rate': 0.5, 'item_alpha': 0.01, 'user_alpha': 0.1, 'max_sampled': 15, 'loss': 'warp'}\n",
      "Result: train_precision = 0.10909091681241989, test_precision = 0.002921231323853135\n",
      "Step 252 of 486\n",
      "Parameters: {'no_components': 40, 'learning_rate': 0.5, 'item_alpha': 0.01, 'user_alpha': 0.1, 'max_sampled': 15, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.15386463701725006, test_precision = 0.002086593536660075\n",
      "Step 253 of 486\n",
      "Parameters: {'no_components': 40, 'learning_rate': 0.5, 'item_alpha': 0.1, 'user_alpha': 0.001, 'max_sampled': 5, 'loss': 'warp'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: train_precision = 0.15778936445713043, test_precision = 0.0021909233182668686\n",
      "Step 254 of 486\n",
      "Parameters: {'no_components': 40, 'learning_rate': 0.5, 'item_alpha': 0.1, 'user_alpha': 0.001, 'max_sampled': 5, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.18285945057868958, test_precision = 0.001147626549936831\n",
      "Step 255 of 486\n",
      "Parameters: {'no_components': 40, 'learning_rate': 0.5, 'item_alpha': 0.1, 'user_alpha': 0.001, 'max_sampled': 10, 'loss': 'warp'}\n",
      "Result: train_precision = 0.15907089412212372, test_precision = 0.002295253099873662\n",
      "Step 256 of 486\n",
      "Parameters: {'no_components': 40, 'learning_rate': 0.5, 'item_alpha': 0.1, 'user_alpha': 0.001, 'max_sampled': 10, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.1767721325159073, test_precision = 0.0019822639878839254\n",
      "Step 257 of 486\n",
      "Parameters: {'no_components': 40, 'learning_rate': 0.5, 'item_alpha': 0.1, 'user_alpha': 0.001, 'max_sampled': 15, 'loss': 'warp'}\n",
      "Result: train_precision = 0.15402483940124512, test_precision = 0.0027125715278089046\n",
      "Step 258 of 486\n",
      "Parameters: {'no_components': 40, 'learning_rate': 0.5, 'item_alpha': 0.1, 'user_alpha': 0.001, 'max_sampled': 15, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.18061676621437073, test_precision = 0.001147626549936831\n",
      "Step 259 of 486\n",
      "Parameters: {'no_components': 40, 'learning_rate': 0.5, 'item_alpha': 0.1, 'user_alpha': 0.01, 'max_sampled': 5, 'loss': 'warp'}\n",
      "Result: train_precision = 0.1537044495344162, test_precision = 0.003025560872629285\n",
      "Step 260 of 486\n",
      "Parameters: {'no_components': 40, 'learning_rate': 0.5, 'item_alpha': 0.1, 'user_alpha': 0.01, 'max_sampled': 5, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.21193435788154602, test_precision = 0.0010432967683300376\n",
      "Step 261 of 486\n",
      "Parameters: {'no_components': 40, 'learning_rate': 0.5, 'item_alpha': 0.1, 'user_alpha': 0.01, 'max_sampled': 10, 'loss': 'warp'}\n",
      "Result: train_precision = 0.1550660878419876, test_precision = 0.006468439940363169\n",
      "Step 262 of 486\n",
      "Parameters: {'no_components': 40, 'learning_rate': 0.5, 'item_alpha': 0.1, 'user_alpha': 0.01, 'max_sampled': 10, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.18117742240428925, test_precision = 0.001877934206277132\n",
      "Step 263 of 486\n",
      "Parameters: {'no_components': 40, 'learning_rate': 0.5, 'item_alpha': 0.1, 'user_alpha': 0.01, 'max_sampled': 15, 'loss': 'warp'}\n",
      "Result: train_precision = 0.15586704015731812, test_precision = 0.0033385497517883778\n",
      "Step 264 of 486\n",
      "Parameters: {'no_components': 40, 'learning_rate': 0.5, 'item_alpha': 0.1, 'user_alpha': 0.01, 'max_sampled': 15, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.17292752861976624, test_precision = 0.002086593536660075\n",
      "Step 265 of 486\n",
      "Parameters: {'no_components': 40, 'learning_rate': 0.5, 'item_alpha': 0.1, 'user_alpha': 0.1, 'max_sampled': 5, 'loss': 'warp'}\n",
      "Result: train_precision = 0.21041253209114075, test_precision = 0.0016692748758941889\n",
      "Step 266 of 486\n",
      "Parameters: {'no_components': 40, 'learning_rate': 0.5, 'item_alpha': 0.1, 'user_alpha': 0.1, 'max_sampled': 5, 'loss': 'bpr'}\n",
      "Error ocurred, skipping prameter\n",
      "Step 267 of 486\n",
      "Parameters: {'no_components': 40, 'learning_rate': 0.5, 'item_alpha': 0.1, 'user_alpha': 0.1, 'max_sampled': 10, 'loss': 'warp'}\n",
      "Result: train_precision = 0.21097318828105927, test_precision = 0.001877934206277132\n",
      "Step 268 of 486\n",
      "Parameters: {'no_components': 40, 'learning_rate': 0.5, 'item_alpha': 0.1, 'user_alpha': 0.1, 'max_sampled': 10, 'loss': 'bpr'}\n",
      "Error ocurred, skipping prameter\n",
      "Step 269 of 486\n",
      "Parameters: {'no_components': 40, 'learning_rate': 0.5, 'item_alpha': 0.1, 'user_alpha': 0.1, 'max_sampled': 15, 'loss': 'warp'}\n",
      "Result: train_precision = 0.21097318828105927, test_precision = 0.001877934206277132\n",
      "Step 270 of 486\n",
      "Parameters: {'no_components': 40, 'learning_rate': 0.5, 'item_alpha': 0.1, 'user_alpha': 0.1, 'max_sampled': 15, 'loss': 'bpr'}\n",
      "Error ocurred, skipping prameter\n",
      "Step 271 of 486\n",
      "Parameters: {'no_components': 40, 'learning_rate': 1, 'item_alpha': 0.001, 'user_alpha': 0.001, 'max_sampled': 5, 'loss': 'warp'}\n",
      "Result: train_precision = 0.07585101574659348, test_precision = 0.0023995828814804554\n",
      "Step 272 of 486\n",
      "Parameters: {'no_components': 40, 'learning_rate': 1, 'item_alpha': 0.001, 'user_alpha': 0.001, 'max_sampled': 5, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.29026833176612854, test_precision = 0.00417318707332015\n",
      "Step 273 of 486\n",
      "Parameters: {'no_components': 40, 'learning_rate': 1, 'item_alpha': 0.001, 'user_alpha': 0.001, 'max_sampled': 10, 'loss': 'warp'}\n",
      "Result: train_precision = 0.07785342633724213, test_precision = 0.002608241979032755\n",
      "Step 274 of 486\n",
      "Parameters: {'no_components': 40, 'learning_rate': 1, 'item_alpha': 0.001, 'user_alpha': 0.001, 'max_sampled': 10, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.14088907837867737, test_precision = 0.0015649452107027173\n",
      "Step 275 of 486\n",
      "Parameters: {'no_components': 40, 'learning_rate': 1, 'item_alpha': 0.001, 'user_alpha': 0.001, 'max_sampled': 15, 'loss': 'warp'}\n",
      "Result: train_precision = 0.10156187415122986, test_precision = 0.0023995828814804554\n",
      "Step 276 of 486\n",
      "Parameters: {'no_components': 40, 'learning_rate': 1, 'item_alpha': 0.001, 'user_alpha': 0.001, 'max_sampled': 15, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.29851824045181274, test_precision = 0.001877934206277132\n",
      "Step 277 of 486\n",
      "Parameters: {'no_components': 40, 'learning_rate': 1, 'item_alpha': 0.001, 'user_alpha': 0.01, 'max_sampled': 5, 'loss': 'warp'}\n",
      "Result: train_precision = 0.1022026389837265, test_precision = 0.002921231323853135\n",
      "Step 278 of 486\n",
      "Parameters: {'no_components': 40, 'learning_rate': 1, 'item_alpha': 0.001, 'user_alpha': 0.01, 'max_sampled': 5, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.14024829864501953, test_precision = 0.0009389671613462269\n",
      "Step 279 of 486\n",
      "Parameters: {'no_components': 40, 'learning_rate': 1, 'item_alpha': 0.001, 'user_alpha': 0.01, 'max_sampled': 10, 'loss': 'warp'}\n",
      "Result: train_precision = 0.07585102319717407, test_precision = 0.003025560872629285\n",
      "Step 280 of 486\n",
      "Parameters: {'no_components': 40, 'learning_rate': 1, 'item_alpha': 0.001, 'user_alpha': 0.01, 'max_sampled': 10, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.2875450551509857, test_precision = 0.0017736046575009823\n",
      "Step 281 of 486\n",
      "Parameters: {'no_components': 40, 'learning_rate': 1, 'item_alpha': 0.001, 'user_alpha': 0.01, 'max_sampled': 15, 'loss': 'warp'}\n",
      "Result: train_precision = 0.11285543441772461, test_precision = 0.0036515388637781143\n",
      "Step 282 of 486\n",
      "Parameters: {'no_components': 40, 'learning_rate': 1, 'item_alpha': 0.001, 'user_alpha': 0.01, 'max_sampled': 15, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.141529843211174, test_precision = 0.0015649453271180391\n",
      "Step 283 of 486\n",
      "Parameters: {'no_components': 40, 'learning_rate': 1, 'item_alpha': 0.001, 'user_alpha': 0.1, 'max_sampled': 5, 'loss': 'warp'}\n",
      "Result: train_precision = 0.10877052694559097, test_precision = 0.002503912430256605\n",
      "Step 284 of 486\n",
      "Parameters: {'no_components': 40, 'learning_rate': 1, 'item_alpha': 0.001, 'user_alpha': 0.1, 'max_sampled': 5, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.14409293234348297, test_precision = 0.001147626549936831\n",
      "Step 285 of 486\n",
      "Parameters: {'no_components': 40, 'learning_rate': 1, 'item_alpha': 0.001, 'user_alpha': 0.1, 'max_sampled': 10, 'loss': 'warp'}\n",
      "Result: train_precision = 0.09162995964288712, test_precision = 0.002086593536660075\n",
      "Step 286 of 486\n",
      "Parameters: {'no_components': 40, 'learning_rate': 1, 'item_alpha': 0.001, 'user_alpha': 0.1, 'max_sampled': 10, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.14353224635124207, test_precision = 0.0009389671613462269\n",
      "Step 287 of 486\n",
      "Parameters: {'no_components': 40, 'learning_rate': 1, 'item_alpha': 0.001, 'user_alpha': 0.1, 'max_sampled': 15, 'loss': 'warp'}\n",
      "Result: train_precision = 0.10156187415122986, test_precision = 0.0036515388637781143\n",
      "Step 288 of 486\n",
      "Parameters: {'no_components': 40, 'learning_rate': 1, 'item_alpha': 0.001, 'user_alpha': 0.1, 'max_sampled': 15, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.14809772372245789, test_precision = 0.0033385497517883778\n",
      "Step 289 of 486\n",
      "Parameters: {'no_components': 40, 'learning_rate': 1, 'item_alpha': 0.01, 'user_alpha': 0.001, 'max_sampled': 5, 'loss': 'warp'}\n",
      "Result: train_precision = 0.08153785020112991, test_precision = 0.003025560872629285\n",
      "Step 290 of 486\n",
      "Parameters: {'no_components': 40, 'learning_rate': 1, 'item_alpha': 0.01, 'user_alpha': 0.001, 'max_sampled': 5, 'loss': 'bpr'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: train_precision = 0.14345215260982513, test_precision = 0.0033385497517883778\n",
      "Step 291 of 486\n",
      "Parameters: {'no_components': 40, 'learning_rate': 1, 'item_alpha': 0.01, 'user_alpha': 0.001, 'max_sampled': 10, 'loss': 'warp'}\n",
      "Result: train_precision = 0.07729274779558182, test_precision = 0.0023995828814804554\n",
      "Step 292 of 486\n",
      "Parameters: {'no_components': 40, 'learning_rate': 1, 'item_alpha': 0.01, 'user_alpha': 0.001, 'max_sampled': 10, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.14449340105056763, test_precision = 0.0023995826486498117\n",
      "Step 293 of 486\n",
      "Parameters: {'no_components': 40, 'learning_rate': 1, 'item_alpha': 0.01, 'user_alpha': 0.001, 'max_sampled': 15, 'loss': 'warp'}\n",
      "Result: train_precision = 0.18013617396354675, test_precision = 0.0016692748758941889\n",
      "Step 294 of 486\n",
      "Parameters: {'no_components': 40, 'learning_rate': 1, 'item_alpha': 0.01, 'user_alpha': 0.001, 'max_sampled': 15, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.1462555080652237, test_precision = 0.0021909233182668686\n",
      "Step 295 of 486\n",
      "Parameters: {'no_components': 40, 'learning_rate': 1, 'item_alpha': 0.01, 'user_alpha': 0.01, 'max_sampled': 5, 'loss': 'warp'}\n",
      "Result: train_precision = 0.07408890873193741, test_precision = 0.002608241979032755\n",
      "Step 296 of 486\n",
      "Parameters: {'no_components': 40, 'learning_rate': 1, 'item_alpha': 0.01, 'user_alpha': 0.01, 'max_sampled': 5, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.15602724254131317, test_precision = 0.0019822639878839254\n",
      "Step 297 of 486\n",
      "Parameters: {'no_components': 40, 'learning_rate': 1, 'item_alpha': 0.01, 'user_alpha': 0.01, 'max_sampled': 10, 'loss': 'warp'}\n",
      "Result: train_precision = 0.07913496345281601, test_precision = 0.002503912430256605\n",
      "Step 298 of 486\n",
      "Parameters: {'no_components': 40, 'learning_rate': 1, 'item_alpha': 0.01, 'user_alpha': 0.01, 'max_sampled': 10, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.14721667766571045, test_precision = 0.002086593536660075\n",
      "Step 299 of 486\n",
      "Parameters: {'no_components': 40, 'learning_rate': 1, 'item_alpha': 0.01, 'user_alpha': 0.01, 'max_sampled': 15, 'loss': 'warp'}\n",
      "Result: train_precision = 0.10196235775947571, test_precision = 0.003651539096608758\n",
      "Step 300 of 486\n",
      "Parameters: {'no_components': 40, 'learning_rate': 1, 'item_alpha': 0.01, 'user_alpha': 0.01, 'max_sampled': 15, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.14505407214164734, test_precision = 0.002295253099873662\n",
      "Step 301 of 486\n",
      "Parameters: {'no_components': 40, 'learning_rate': 1, 'item_alpha': 0.01, 'user_alpha': 0.1, 'max_sampled': 5, 'loss': 'warp'}\n",
      "Result: train_precision = 0.08578293770551682, test_precision = 0.002086593536660075\n",
      "Step 302 of 486\n",
      "Parameters: {'no_components': 40, 'learning_rate': 1, 'item_alpha': 0.01, 'user_alpha': 0.1, 'max_sampled': 5, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.4385262429714203, test_precision = 0.0014606156619265676\n",
      "Step 303 of 486\n",
      "Parameters: {'no_components': 40, 'learning_rate': 1, 'item_alpha': 0.01, 'user_alpha': 0.1, 'max_sampled': 10, 'loss': 'warp'}\n",
      "Result: train_precision = 0.2086504101753235, test_precision = 0.003025560872629285\n",
      "Step 304 of 486\n",
      "Parameters: {'no_components': 40, 'learning_rate': 1, 'item_alpha': 0.01, 'user_alpha': 0.1, 'max_sampled': 10, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.15674810111522675, test_precision = 0.001877934206277132\n",
      "Step 305 of 486\n",
      "Parameters: {'no_components': 40, 'learning_rate': 1, 'item_alpha': 0.01, 'user_alpha': 0.1, 'max_sampled': 15, 'loss': 'warp'}\n",
      "Result: train_precision = 0.17132559418678284, test_precision = 0.0006259781075641513\n",
      "Step 306 of 486\n",
      "Parameters: {'no_components': 40, 'learning_rate': 1, 'item_alpha': 0.01, 'user_alpha': 0.1, 'max_sampled': 15, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.16467761993408203, test_precision = 0.0019822639878839254\n",
      "Step 307 of 486\n",
      "Parameters: {'no_components': 40, 'learning_rate': 1, 'item_alpha': 0.1, 'user_alpha': 0.001, 'max_sampled': 5, 'loss': 'warp'}\n",
      "Result: train_precision = 0.19367241859436035, test_precision = 0.0019822639878839254\n",
      "Step 308 of 486\n",
      "Parameters: {'no_components': 40, 'learning_rate': 1, 'item_alpha': 0.1, 'user_alpha': 0.001, 'max_sampled': 5, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.19631560146808624, test_precision = 0.0008346374379470944\n",
      "Step 309 of 486\n",
      "Parameters: {'no_components': 40, 'learning_rate': 1, 'item_alpha': 0.1, 'user_alpha': 0.001, 'max_sampled': 10, 'loss': 'warp'}\n",
      "Result: train_precision = 0.20464558899402618, test_precision = 0.0028169015422463417\n",
      "Step 310 of 486\n",
      "Parameters: {'no_components': 40, 'learning_rate': 1, 'item_alpha': 0.1, 'user_alpha': 0.001, 'max_sampled': 10, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.1746896505355835, test_precision = 0.0028169015422463417\n",
      "Step 311 of 486\n",
      "Parameters: {'no_components': 40, 'learning_rate': 1, 'item_alpha': 0.1, 'user_alpha': 0.001, 'max_sampled': 15, 'loss': 'warp'}\n",
      "Result: train_precision = 0.2001602053642273, test_precision = 0.002086593536660075\n",
      "Step 312 of 486\n",
      "Parameters: {'no_components': 40, 'learning_rate': 1, 'item_alpha': 0.1, 'user_alpha': 0.001, 'max_sampled': 15, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.19126953184604645, test_precision = 0.0016692748758941889\n",
      "Step 313 of 486\n",
      "Parameters: {'no_components': 40, 'learning_rate': 1, 'item_alpha': 0.1, 'user_alpha': 0.01, 'max_sampled': 5, 'loss': 'warp'}\n",
      "Result: train_precision = 0.19287146627902985, test_precision = 0.0016692748758941889\n",
      "Step 314 of 486\n",
      "Parameters: {'no_components': 40, 'learning_rate': 1, 'item_alpha': 0.1, 'user_alpha': 0.01, 'max_sampled': 5, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.20592714846134186, test_precision = 0.0008346374379470944\n",
      "Step 315 of 486\n",
      "Parameters: {'no_components': 40, 'learning_rate': 1, 'item_alpha': 0.1, 'user_alpha': 0.01, 'max_sampled': 10, 'loss': 'warp'}\n",
      "Result: train_precision = 0.21385665237903595, test_precision = 0.002086593536660075\n",
      "Step 316 of 486\n",
      "Parameters: {'no_components': 40, 'learning_rate': 1, 'item_alpha': 0.1, 'user_alpha': 0.01, 'max_sampled': 10, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.1895875185728073, test_precision = 0.0013562857639044523\n",
      "Step 317 of 486\n",
      "Parameters: {'no_components': 40, 'learning_rate': 1, 'item_alpha': 0.1, 'user_alpha': 0.01, 'max_sampled': 15, 'loss': 'warp'}\n",
      "Result: train_precision = 0.20104128122329712, test_precision = 0.0021909233182668686\n",
      "Step 318 of 486\n",
      "Parameters: {'no_components': 40, 'learning_rate': 1, 'item_alpha': 0.1, 'user_alpha': 0.01, 'max_sampled': 15, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.2071285843849182, test_precision = 0.0013562857639044523\n",
      "Step 319 of 486\n",
      "Parameters: {'no_components': 40, 'learning_rate': 1, 'item_alpha': 0.1, 'user_alpha': 0.1, 'max_sampled': 5, 'loss': 'warp'}\n",
      "Result: train_precision = 0.20584703981876373, test_precision = 0.001877934206277132\n",
      "Step 320 of 486\n",
      "Parameters: {'no_components': 40, 'learning_rate': 1, 'item_alpha': 0.1, 'user_alpha': 0.1, 'max_sampled': 5, 'loss': 'bpr'}\n",
      "Error ocurred, skipping prameter\n",
      "Step 321 of 486\n",
      "Parameters: {'no_components': 40, 'learning_rate': 1, 'item_alpha': 0.1, 'user_alpha': 0.1, 'max_sampled': 10, 'loss': 'warp'}\n",
      "Result: train_precision = 0.09923909604549408, test_precision = 0.001669274759478867\n",
      "Step 322 of 486\n",
      "Parameters: {'no_components': 40, 'learning_rate': 1, 'item_alpha': 0.1, 'user_alpha': 0.1, 'max_sampled': 10, 'loss': 'bpr'}\n",
      "Error ocurred, skipping prameter\n",
      "Step 323 of 486\n",
      "Parameters: {'no_components': 40, 'learning_rate': 1, 'item_alpha': 0.1, 'user_alpha': 0.1, 'max_sampled': 15, 'loss': 'warp'}\n",
      "Result: train_precision = 0.1550660878419876, test_precision = 0.002608241979032755\n",
      "Step 324 of 486\n",
      "Parameters: {'no_components': 40, 'learning_rate': 1, 'item_alpha': 0.1, 'user_alpha': 0.1, 'max_sampled': 15, 'loss': 'bpr'}\n",
      "Error ocurred, skipping prameter\n",
      "Step 325 of 486\n",
      "Parameters: {'no_components': 64, 'learning_rate': 0.05, 'item_alpha': 0.001, 'user_alpha': 0.001, 'max_sampled': 5, 'loss': 'warp'}\n",
      "Result: train_precision = 0.28450140357017517, test_precision = 0.0018779343226924539\n",
      "Step 326 of 486\n",
      "Parameters: {'no_components': 64, 'learning_rate': 0.05, 'item_alpha': 0.001, 'user_alpha': 0.001, 'max_sampled': 5, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.15786944329738617, test_precision = 0.00417318707332015\n",
      "Step 327 of 486\n",
      "Parameters: {'no_components': 64, 'learning_rate': 0.05, 'item_alpha': 0.001, 'user_alpha': 0.001, 'max_sampled': 10, 'loss': 'warp'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: train_precision = 0.29106929898262024, test_precision = 0.0016692748758941889\n",
      "Step 328 of 486\n",
      "Parameters: {'no_components': 64, 'learning_rate': 0.05, 'item_alpha': 0.001, 'user_alpha': 0.001, 'max_sampled': 10, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.2020024061203003, test_precision = 0.0015649452107027173\n",
      "Step 329 of 486\n",
      "Parameters: {'no_components': 64, 'learning_rate': 0.05, 'item_alpha': 0.001, 'user_alpha': 0.001, 'max_sampled': 15, 'loss': 'warp'}\n",
      "Result: train_precision = 0.2919503450393677, test_precision = 0.0021909233182668686\n",
      "Step 330 of 486\n",
      "Parameters: {'no_components': 64, 'learning_rate': 0.05, 'item_alpha': 0.001, 'user_alpha': 0.001, 'max_sampled': 15, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.34873849153518677, test_precision = 0.0017736046575009823\n",
      "Step 331 of 486\n",
      "Parameters: {'no_components': 64, 'learning_rate': 0.05, 'item_alpha': 0.001, 'user_alpha': 0.01, 'max_sampled': 5, 'loss': 'warp'}\n",
      "Result: train_precision = 0.2905086576938629, test_precision = 0.0014606156619265676\n",
      "Step 332 of 486\n",
      "Parameters: {'no_components': 64, 'learning_rate': 0.05, 'item_alpha': 0.001, 'user_alpha': 0.01, 'max_sampled': 5, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.1898278146982193, test_precision = 0.0015649452107027173\n",
      "Step 333 of 486\n",
      "Parameters: {'no_components': 64, 'learning_rate': 0.05, 'item_alpha': 0.001, 'user_alpha': 0.01, 'max_sampled': 10, 'loss': 'warp'}\n",
      "Result: train_precision = 0.29114940762519836, test_precision = 0.0014606156619265676\n",
      "Step 334 of 486\n",
      "Parameters: {'no_components': 64, 'learning_rate': 0.05, 'item_alpha': 0.001, 'user_alpha': 0.01, 'max_sampled': 10, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.14777734875679016, test_precision = 0.0021909233182668686\n",
      "Step 335 of 486\n",
      "Parameters: {'no_components': 64, 'learning_rate': 0.05, 'item_alpha': 0.001, 'user_alpha': 0.01, 'max_sampled': 15, 'loss': 'warp'}\n",
      "Result: train_precision = 0.2922707498073578, test_precision = 0.0014606156619265676\n",
      "Step 336 of 486\n",
      "Parameters: {'no_components': 64, 'learning_rate': 0.05, 'item_alpha': 0.001, 'user_alpha': 0.01, 'max_sampled': 15, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.17717261612415314, test_precision = 0.002921231323853135\n",
      "Step 337 of 486\n",
      "Parameters: {'no_components': 64, 'learning_rate': 0.05, 'item_alpha': 0.001, 'user_alpha': 0.1, 'max_sampled': 5, 'loss': 'warp'}\n",
      "Result: train_precision = 0.29379257559776306, test_precision = 0.0013562858803197742\n",
      "Step 338 of 486\n",
      "Parameters: {'no_components': 64, 'learning_rate': 0.05, 'item_alpha': 0.001, 'user_alpha': 0.1, 'max_sampled': 5, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.14112935960292816, test_precision = 0.003234220203012228\n",
      "Step 339 of 486\n",
      "Parameters: {'no_components': 64, 'learning_rate': 0.05, 'item_alpha': 0.001, 'user_alpha': 0.1, 'max_sampled': 10, 'loss': 'warp'}\n",
      "Result: train_precision = 0.29395273327827454, test_precision = 0.0013562858803197742\n",
      "Step 340 of 486\n",
      "Parameters: {'no_components': 64, 'learning_rate': 0.05, 'item_alpha': 0.001, 'user_alpha': 0.1, 'max_sampled': 10, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.14136965572834015, test_precision = 0.00500782486051321\n",
      "Step 341 of 486\n",
      "Parameters: {'no_components': 64, 'learning_rate': 0.05, 'item_alpha': 0.001, 'user_alpha': 0.1, 'max_sampled': 15, 'loss': 'warp'}\n",
      "Result: train_precision = 0.2941129505634308, test_precision = 0.0013562858803197742\n",
      "Step 342 of 486\n",
      "Parameters: {'no_components': 64, 'learning_rate': 0.05, 'item_alpha': 0.001, 'user_alpha': 0.1, 'max_sampled': 15, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.1444133073091507, test_precision = 0.003442879533395171\n",
      "Step 343 of 486\n",
      "Parameters: {'no_components': 64, 'learning_rate': 0.05, 'item_alpha': 0.01, 'user_alpha': 0.001, 'max_sampled': 5, 'loss': 'warp'}\n",
      "Result: train_precision = 0.2909891903400421, test_precision = 0.0013562858803197742\n",
      "Step 344 of 486\n",
      "Parameters: {'no_components': 64, 'learning_rate': 0.05, 'item_alpha': 0.01, 'user_alpha': 0.001, 'max_sampled': 5, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.34929919242858887, test_precision = 0.002086593536660075\n",
      "Step 345 of 486\n",
      "Parameters: {'no_components': 64, 'learning_rate': 0.05, 'item_alpha': 0.01, 'user_alpha': 0.001, 'max_sampled': 10, 'loss': 'warp'}\n",
      "Result: train_precision = 0.2800160348415375, test_precision = 0.0013562858803197742\n",
      "Step 346 of 486\n",
      "Parameters: {'no_components': 64, 'learning_rate': 0.05, 'item_alpha': 0.01, 'user_alpha': 0.001, 'max_sampled': 10, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.2877052426338196, test_precision = 0.0016692748758941889\n",
      "Step 347 of 486\n",
      "Parameters: {'no_components': 64, 'learning_rate': 0.05, 'item_alpha': 0.01, 'user_alpha': 0.001, 'max_sampled': 15, 'loss': 'warp'}\n",
      "Result: train_precision = 0.28522229194641113, test_precision = 0.0013562858803197742\n",
      "Step 348 of 486\n",
      "Parameters: {'no_components': 64, 'learning_rate': 0.05, 'item_alpha': 0.01, 'user_alpha': 0.001, 'max_sampled': 15, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.3063676357269287, test_precision = 0.0019822639878839254\n",
      "Step 349 of 486\n",
      "Parameters: {'no_components': 64, 'learning_rate': 0.05, 'item_alpha': 0.01, 'user_alpha': 0.01, 'max_sampled': 5, 'loss': 'warp'}\n",
      "Result: train_precision = 0.29323190450668335, test_precision = 0.0013562858803197742\n",
      "Step 350 of 486\n",
      "Parameters: {'no_components': 64, 'learning_rate': 0.05, 'item_alpha': 0.01, 'user_alpha': 0.01, 'max_sampled': 5, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.17957551777362823, test_precision = 0.0010432967683300376\n",
      "Step 351 of 486\n",
      "Parameters: {'no_components': 64, 'learning_rate': 0.05, 'item_alpha': 0.01, 'user_alpha': 0.01, 'max_sampled': 10, 'loss': 'warp'}\n",
      "Result: train_precision = 0.29106929898262024, test_precision = 0.0013562858803197742\n",
      "Step 352 of 486\n",
      "Parameters: {'no_components': 64, 'learning_rate': 0.05, 'item_alpha': 0.01, 'user_alpha': 0.01, 'max_sampled': 10, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.4380456805229187, test_precision = 0.0014606156619265676\n",
      "Step 353 of 486\n",
      "Parameters: {'no_components': 64, 'learning_rate': 0.05, 'item_alpha': 0.01, 'user_alpha': 0.01, 'max_sampled': 15, 'loss': 'warp'}\n",
      "Result: train_precision = 0.2901081442832947, test_precision = 0.0013562858803197742\n",
      "Step 354 of 486\n",
      "Parameters: {'no_components': 64, 'learning_rate': 0.05, 'item_alpha': 0.01, 'user_alpha': 0.01, 'max_sampled': 15, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.4382859468460083, test_precision = 0.0014606156619265676\n",
      "Step 355 of 486\n",
      "Parameters: {'no_components': 64, 'learning_rate': 0.05, 'item_alpha': 0.01, 'user_alpha': 0.1, 'max_sampled': 5, 'loss': 'warp'}\n",
      "Result: train_precision = 0.2941129505634308, test_precision = 0.0013562858803197742\n",
      "Step 356 of 486\n",
      "Parameters: {'no_components': 64, 'learning_rate': 0.05, 'item_alpha': 0.01, 'user_alpha': 0.1, 'max_sampled': 5, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.1399279087781906, test_precision = 0.0023995828814804554\n",
      "Step 357 of 486\n",
      "Parameters: {'no_components': 64, 'learning_rate': 0.05, 'item_alpha': 0.01, 'user_alpha': 0.1, 'max_sampled': 10, 'loss': 'warp'}\n",
      "Result: train_precision = 0.2941129505634308, test_precision = 0.0013562858803197742\n",
      "Step 358 of 486\n",
      "Parameters: {'no_components': 64, 'learning_rate': 0.05, 'item_alpha': 0.01, 'user_alpha': 0.1, 'max_sampled': 10, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.152102530002594, test_precision = 0.002608241979032755\n",
      "Step 359 of 486\n",
      "Parameters: {'no_components': 64, 'learning_rate': 0.05, 'item_alpha': 0.01, 'user_alpha': 0.1, 'max_sampled': 15, 'loss': 'warp'}\n",
      "Result: train_precision = 0.2941129505634308, test_precision = 0.0013562858803197742\n",
      "Step 360 of 486\n",
      "Parameters: {'no_components': 64, 'learning_rate': 0.05, 'item_alpha': 0.01, 'user_alpha': 0.1, 'max_sampled': 15, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.1393672525882721, test_precision = 0.0028169015422463417\n",
      "Step 361 of 486\n",
      "Parameters: {'no_components': 64, 'learning_rate': 0.05, 'item_alpha': 0.1, 'user_alpha': 0.001, 'max_sampled': 5, 'loss': 'warp'}\n",
      "Result: train_precision = 0.17076492309570312, test_precision = 0.0012519562151283026\n",
      "Step 362 of 486\n",
      "Parameters: {'no_components': 64, 'learning_rate': 0.05, 'item_alpha': 0.1, 'user_alpha': 0.001, 'max_sampled': 5, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.1866239756345749, test_precision = 0.0031298904214054346\n",
      "Step 363 of 486\n",
      "Parameters: {'no_components': 64, 'learning_rate': 0.05, 'item_alpha': 0.1, 'user_alpha': 0.001, 'max_sampled': 10, 'loss': 'warp'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: train_precision = 0.2375650852918625, test_precision = 0.0007303077727556229\n",
      "Step 364 of 486\n",
      "Parameters: {'no_components': 64, 'learning_rate': 0.05, 'item_alpha': 0.1, 'user_alpha': 0.001, 'max_sampled': 10, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.1704445481300354, test_precision = 0.002086593536660075\n",
      "Step 365 of 486\n",
      "Parameters: {'no_components': 64, 'learning_rate': 0.05, 'item_alpha': 0.1, 'user_alpha': 0.001, 'max_sampled': 15, 'loss': 'warp'}\n",
      "Result: train_precision = 0.18806569278240204, test_precision = 0.0016692748758941889\n",
      "Step 366 of 486\n",
      "Parameters: {'no_components': 64, 'learning_rate': 0.05, 'item_alpha': 0.1, 'user_alpha': 0.001, 'max_sampled': 15, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.20328395068645477, test_precision = 0.0017736046575009823\n",
      "Step 367 of 486\n",
      "Parameters: {'no_components': 64, 'learning_rate': 0.05, 'item_alpha': 0.1, 'user_alpha': 0.01, 'max_sampled': 5, 'loss': 'warp'}\n",
      "Result: train_precision = 0.0918702483177185, test_precision = 0.0004173187189735472\n",
      "Step 368 of 486\n",
      "Parameters: {'no_components': 64, 'learning_rate': 0.05, 'item_alpha': 0.1, 'user_alpha': 0.01, 'max_sampled': 5, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.20168203115463257, test_precision = 0.0005216483841650188\n",
      "Step 369 of 486\n",
      "Parameters: {'no_components': 64, 'learning_rate': 0.05, 'item_alpha': 0.1, 'user_alpha': 0.01, 'max_sampled': 10, 'loss': 'warp'}\n",
      "Result: train_precision = 0.2941129505634308, test_precision = 0.0013562858803197742\n",
      "Step 370 of 486\n",
      "Parameters: {'no_components': 64, 'learning_rate': 0.05, 'item_alpha': 0.1, 'user_alpha': 0.01, 'max_sampled': 10, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.20168203115463257, test_precision = 0.0005216483841650188\n",
      "Step 371 of 486\n",
      "Parameters: {'no_components': 64, 'learning_rate': 0.05, 'item_alpha': 0.1, 'user_alpha': 0.01, 'max_sampled': 15, 'loss': 'warp'}\n",
      "Result: train_precision = 0.2784942388534546, test_precision = 0.0019822639878839254\n",
      "Step 372 of 486\n",
      "Parameters: {'no_components': 64, 'learning_rate': 0.05, 'item_alpha': 0.1, 'user_alpha': 0.01, 'max_sampled': 15, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.20184223353862762, test_precision = 0.001147626549936831\n",
      "Step 373 of 486\n",
      "Parameters: {'no_components': 64, 'learning_rate': 0.05, 'item_alpha': 0.1, 'user_alpha': 0.1, 'max_sampled': 5, 'loss': 'warp'}\n",
      "Result: train_precision = 0.2941129505634308, test_precision = 0.0013562858803197742\n",
      "Step 374 of 486\n",
      "Parameters: {'no_components': 64, 'learning_rate': 0.05, 'item_alpha': 0.1, 'user_alpha': 0.1, 'max_sampled': 5, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.21097318828105927, test_precision = 0.0016692751087248325\n",
      "Step 375 of 486\n",
      "Parameters: {'no_components': 64, 'learning_rate': 0.05, 'item_alpha': 0.1, 'user_alpha': 0.1, 'max_sampled': 10, 'loss': 'warp'}\n",
      "Result: train_precision = 0.2941129505634308, test_precision = 0.0013562858803197742\n",
      "Step 376 of 486\n",
      "Parameters: {'no_components': 64, 'learning_rate': 0.05, 'item_alpha': 0.1, 'user_alpha': 0.1, 'max_sampled': 10, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.21097318828105927, test_precision = 0.001877934206277132\n",
      "Step 377 of 486\n",
      "Parameters: {'no_components': 64, 'learning_rate': 0.05, 'item_alpha': 0.1, 'user_alpha': 0.1, 'max_sampled': 15, 'loss': 'warp'}\n",
      "Result: train_precision = 0.2941129505634308, test_precision = 0.0013562858803197742\n",
      "Step 378 of 486\n",
      "Parameters: {'no_components': 64, 'learning_rate': 0.05, 'item_alpha': 0.1, 'user_alpha': 0.1, 'max_sampled': 15, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.21097318828105927, test_precision = 0.001877934206277132\n",
      "Step 379 of 486\n",
      "Parameters: {'no_components': 64, 'learning_rate': 0.5, 'item_alpha': 0.001, 'user_alpha': 0.001, 'max_sampled': 5, 'loss': 'warp'}\n",
      "Result: train_precision = 0.058790549635887146, test_precision = 0.0016692748758941889\n",
      "Step 380 of 486\n",
      "Parameters: {'no_components': 64, 'learning_rate': 0.5, 'item_alpha': 0.001, 'user_alpha': 0.001, 'max_sampled': 5, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.14345215260982513, test_precision = 0.0021909233182668686\n",
      "Step 381 of 486\n",
      "Parameters: {'no_components': 64, 'learning_rate': 0.5, 'item_alpha': 0.001, 'user_alpha': 0.001, 'max_sampled': 10, 'loss': 'warp'}\n",
      "Result: train_precision = 0.10284340381622314, test_precision = 0.0032342199701815844\n",
      "Step 382 of 486\n",
      "Parameters: {'no_components': 64, 'learning_rate': 0.5, 'item_alpha': 0.001, 'user_alpha': 0.001, 'max_sampled': 10, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.14729677140712738, test_precision = 0.0037558686453849077\n",
      "Step 383 of 486\n",
      "Parameters: {'no_components': 64, 'learning_rate': 0.5, 'item_alpha': 0.001, 'user_alpha': 0.001, 'max_sampled': 15, 'loss': 'warp'}\n",
      "Result: train_precision = 0.18630357086658478, test_precision = 0.0016692748758941889\n",
      "Step 384 of 486\n",
      "Parameters: {'no_components': 64, 'learning_rate': 0.5, 'item_alpha': 0.001, 'user_alpha': 0.001, 'max_sampled': 15, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.14753705263137817, test_precision = 0.002295253099873662\n",
      "Step 385 of 486\n",
      "Parameters: {'no_components': 64, 'learning_rate': 0.5, 'item_alpha': 0.001, 'user_alpha': 0.01, 'max_sampled': 5, 'loss': 'warp'}\n",
      "Result: train_precision = 0.09162995964288712, test_precision = 0.0014606156619265676\n",
      "Step 386 of 486\n",
      "Parameters: {'no_components': 64, 'learning_rate': 0.5, 'item_alpha': 0.001, 'user_alpha': 0.01, 'max_sampled': 5, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.14136967062950134, test_precision = 0.003234220203012228\n",
      "Step 387 of 486\n",
      "Parameters: {'no_components': 64, 'learning_rate': 0.5, 'item_alpha': 0.001, 'user_alpha': 0.01, 'max_sampled': 10, 'loss': 'warp'}\n",
      "Result: train_precision = 0.1054064929485321, test_precision = 0.0023995828814804554\n",
      "Step 388 of 486\n",
      "Parameters: {'no_components': 64, 'learning_rate': 0.5, 'item_alpha': 0.001, 'user_alpha': 0.01, 'max_sampled': 10, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.14185023307800293, test_precision = 0.004277517553418875\n",
      "Step 389 of 486\n",
      "Parameters: {'no_components': 64, 'learning_rate': 0.5, 'item_alpha': 0.001, 'user_alpha': 0.01, 'max_sampled': 15, 'loss': 'warp'}\n",
      "Result: train_precision = 0.11061274260282516, test_precision = 0.0035472093150019646\n",
      "Step 390 of 486\n",
      "Parameters: {'no_components': 64, 'learning_rate': 0.5, 'item_alpha': 0.001, 'user_alpha': 0.01, 'max_sampled': 15, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.14321187138557434, test_precision = 0.0035472093150019646\n",
      "Step 391 of 486\n",
      "Parameters: {'no_components': 64, 'learning_rate': 0.5, 'item_alpha': 0.001, 'user_alpha': 0.1, 'max_sampled': 5, 'loss': 'warp'}\n",
      "Result: train_precision = 0.10893071442842484, test_precision = 0.0031298904214054346\n",
      "Step 392 of 486\n",
      "Parameters: {'no_components': 64, 'learning_rate': 0.5, 'item_alpha': 0.001, 'user_alpha': 0.1, 'max_sampled': 5, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.15226271748542786, test_precision = 0.002086593536660075\n",
      "Step 393 of 486\n",
      "Parameters: {'no_components': 64, 'learning_rate': 0.5, 'item_alpha': 0.001, 'user_alpha': 0.1, 'max_sampled': 10, 'loss': 'warp'}\n",
      "Result: train_precision = 0.10845013707876205, test_precision = 0.003964527975767851\n",
      "Step 394 of 486\n",
      "Parameters: {'no_components': 64, 'learning_rate': 0.5, 'item_alpha': 0.001, 'user_alpha': 0.1, 'max_sampled': 10, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.14913897216320038, test_precision = 0.0016692751087248325\n",
      "Step 395 of 486\n",
      "Parameters: {'no_components': 64, 'learning_rate': 0.5, 'item_alpha': 0.001, 'user_alpha': 0.1, 'max_sampled': 15, 'loss': 'warp'}\n",
      "Result: train_precision = 0.11045254021883011, test_precision = 0.004486176650971174\n",
      "Step 396 of 486\n",
      "Parameters: {'no_components': 64, 'learning_rate': 0.5, 'item_alpha': 0.001, 'user_alpha': 0.1, 'max_sampled': 15, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.29827794432640076, test_precision = 0.001877934206277132\n",
      "Step 397 of 486\n",
      "Parameters: {'no_components': 64, 'learning_rate': 0.5, 'item_alpha': 0.01, 'user_alpha': 0.001, 'max_sampled': 5, 'loss': 'warp'}\n",
      "Result: train_precision = 0.1847817450761795, test_precision = 0.0036515388637781143\n",
      "Step 398 of 486\n",
      "Parameters: {'no_components': 64, 'learning_rate': 0.5, 'item_alpha': 0.01, 'user_alpha': 0.001, 'max_sampled': 5, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.15074089169502258, test_precision = 0.002295253099873662\n",
      "Step 399 of 486\n",
      "Parameters: {'no_components': 64, 'learning_rate': 0.5, 'item_alpha': 0.01, 'user_alpha': 0.001, 'max_sampled': 10, 'loss': 'warp'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: train_precision = 0.06167401000857353, test_precision = 0.002086593536660075\n",
      "Step 400 of 486\n",
      "Parameters: {'no_components': 64, 'learning_rate': 0.5, 'item_alpha': 0.01, 'user_alpha': 0.001, 'max_sampled': 10, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.150020033121109, test_precision = 0.0023995826486498117\n",
      "Step 401 of 486\n",
      "Parameters: {'no_components': 64, 'learning_rate': 0.5, 'item_alpha': 0.01, 'user_alpha': 0.001, 'max_sampled': 15, 'loss': 'warp'}\n",
      "Result: train_precision = 0.08858630806207657, test_precision = 0.0015649452107027173\n",
      "Step 402 of 486\n",
      "Parameters: {'no_components': 64, 'learning_rate': 0.5, 'item_alpha': 0.01, 'user_alpha': 0.001, 'max_sampled': 15, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.1465758979320526, test_precision = 0.002295253099873662\n",
      "Step 403 of 486\n",
      "Parameters: {'no_components': 64, 'learning_rate': 0.5, 'item_alpha': 0.01, 'user_alpha': 0.01, 'max_sampled': 5, 'loss': 'warp'}\n",
      "Result: train_precision = 0.07969563454389572, test_precision = 0.0027125717606395483\n",
      "Step 404 of 486\n",
      "Parameters: {'no_components': 64, 'learning_rate': 0.5, 'item_alpha': 0.01, 'user_alpha': 0.01, 'max_sampled': 5, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.14913897216320038, test_precision = 0.0027125715278089046\n",
      "Step 405 of 486\n",
      "Parameters: {'no_components': 64, 'learning_rate': 0.5, 'item_alpha': 0.01, 'user_alpha': 0.01, 'max_sampled': 10, 'loss': 'warp'}\n",
      "Result: train_precision = 0.07905486226081848, test_precision = 0.004694835748523474\n",
      "Step 406 of 486\n",
      "Parameters: {'no_components': 64, 'learning_rate': 0.5, 'item_alpha': 0.01, 'user_alpha': 0.01, 'max_sampled': 10, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.14809773862361908, test_precision = 0.0023995828814804554\n",
      "Step 407 of 486\n",
      "Parameters: {'no_components': 64, 'learning_rate': 0.5, 'item_alpha': 0.01, 'user_alpha': 0.01, 'max_sampled': 15, 'loss': 'warp'}\n",
      "Result: train_precision = 0.10364437848329544, test_precision = 0.0035472093150019646\n",
      "Step 408 of 486\n",
      "Parameters: {'no_components': 64, 'learning_rate': 0.5, 'item_alpha': 0.01, 'user_alpha': 0.01, 'max_sampled': 15, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.14561475813388824, test_precision = 0.0029212310910224915\n",
      "Step 409 of 486\n",
      "Parameters: {'no_components': 64, 'learning_rate': 0.5, 'item_alpha': 0.01, 'user_alpha': 0.1, 'max_sampled': 5, 'loss': 'warp'}\n",
      "Result: train_precision = 0.07897477596998215, test_precision = 0.0033385497517883778\n",
      "Step 410 of 486\n",
      "Parameters: {'no_components': 64, 'learning_rate': 0.5, 'item_alpha': 0.01, 'user_alpha': 0.1, 'max_sampled': 5, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.15306368470191956, test_precision = 0.0027125715278089046\n",
      "Step 411 of 486\n",
      "Parameters: {'no_components': 64, 'learning_rate': 0.5, 'item_alpha': 0.01, 'user_alpha': 0.1, 'max_sampled': 10, 'loss': 'warp'}\n",
      "Result: train_precision = 0.07681218534708023, test_precision = 0.002921231323853135\n",
      "Step 412 of 486\n",
      "Parameters: {'no_components': 64, 'learning_rate': 0.5, 'item_alpha': 0.01, 'user_alpha': 0.1, 'max_sampled': 10, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.14913897216320038, test_precision = 0.0017736046575009823\n",
      "Step 413 of 486\n",
      "Parameters: {'no_components': 64, 'learning_rate': 0.5, 'item_alpha': 0.01, 'user_alpha': 0.1, 'max_sampled': 15, 'loss': 'warp'}\n",
      "Result: train_precision = 0.1072487086057663, test_precision = 0.008033386431634426\n",
      "Step 414 of 486\n",
      "Parameters: {'no_components': 64, 'learning_rate': 0.5, 'item_alpha': 0.01, 'user_alpha': 0.1, 'max_sampled': 15, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.14769724011421204, test_precision = 0.0017736046575009823\n",
      "Step 415 of 486\n",
      "Parameters: {'no_components': 64, 'learning_rate': 0.5, 'item_alpha': 0.1, 'user_alpha': 0.001, 'max_sampled': 5, 'loss': 'warp'}\n",
      "Result: train_precision = 0.1547456979751587, test_precision = 0.0061554512940347195\n",
      "Step 416 of 486\n",
      "Parameters: {'no_components': 64, 'learning_rate': 0.5, 'item_alpha': 0.1, 'user_alpha': 0.001, 'max_sampled': 5, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.17244695127010345, test_precision = 0.001147626549936831\n",
      "Step 417 of 486\n",
      "Parameters: {'no_components': 64, 'learning_rate': 0.5, 'item_alpha': 0.1, 'user_alpha': 0.001, 'max_sampled': 10, 'loss': 'warp'}\n",
      "Result: train_precision = 0.16411694884300232, test_precision = 0.0023995826486498117\n",
      "Step 418 of 486\n",
      "Parameters: {'no_components': 64, 'learning_rate': 0.5, 'item_alpha': 0.1, 'user_alpha': 0.001, 'max_sampled': 10, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.14873848855495453, test_precision = 0.0012519562151283026\n",
      "Step 419 of 486\n",
      "Parameters: {'no_components': 64, 'learning_rate': 0.5, 'item_alpha': 0.1, 'user_alpha': 0.001, 'max_sampled': 15, 'loss': 'warp'}\n",
      "Result: train_precision = 0.1579495519399643, test_precision = 0.0027125715278089046\n",
      "Step 420 of 486\n",
      "Parameters: {'no_components': 64, 'learning_rate': 0.5, 'item_alpha': 0.1, 'user_alpha': 0.001, 'max_sampled': 15, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.18085704743862152, test_precision = 0.0016692748758941889\n",
      "Step 421 of 486\n",
      "Parameters: {'no_components': 64, 'learning_rate': 0.5, 'item_alpha': 0.1, 'user_alpha': 0.01, 'max_sampled': 5, 'loss': 'warp'}\n",
      "Result: train_precision = 0.15867041051387787, test_precision = 0.0018779343226924539\n",
      "Step 422 of 486\n",
      "Parameters: {'no_components': 64, 'learning_rate': 0.5, 'item_alpha': 0.1, 'user_alpha': 0.01, 'max_sampled': 5, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.1760512739419937, test_precision = 0.0015649452107027173\n",
      "Step 423 of 486\n",
      "Parameters: {'no_components': 64, 'learning_rate': 0.5, 'item_alpha': 0.1, 'user_alpha': 0.01, 'max_sampled': 10, 'loss': 'warp'}\n",
      "Result: train_precision = 0.15514618158340454, test_precision = 0.002086593536660075\n",
      "Step 424 of 486\n",
      "Parameters: {'no_components': 64, 'learning_rate': 0.5, 'item_alpha': 0.1, 'user_alpha': 0.01, 'max_sampled': 10, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.2110532820224762, test_precision = 0.0015649452107027173\n",
      "Step 425 of 486\n",
      "Parameters: {'no_components': 64, 'learning_rate': 0.5, 'item_alpha': 0.1, 'user_alpha': 0.01, 'max_sampled': 15, 'loss': 'warp'}\n",
      "Result: train_precision = 0.16155387461185455, test_precision = 0.0017736046575009823\n",
      "Step 426 of 486\n",
      "Parameters: {'no_components': 64, 'learning_rate': 0.5, 'item_alpha': 0.1, 'user_alpha': 0.01, 'max_sampled': 15, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.1999199241399765, test_precision = 0.0014606155455112457\n",
      "Step 427 of 486\n",
      "Parameters: {'no_components': 64, 'learning_rate': 0.5, 'item_alpha': 0.1, 'user_alpha': 0.1, 'max_sampled': 5, 'loss': 'warp'}\n",
      "Result: train_precision = 0.18229879438877106, test_precision = 0.002921231323853135\n",
      "Step 428 of 486\n",
      "Parameters: {'no_components': 64, 'learning_rate': 0.5, 'item_alpha': 0.1, 'user_alpha': 0.1, 'max_sampled': 5, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.006647977512329817, test_precision = 0.001877934206277132\n",
      "Step 429 of 486\n",
      "Parameters: {'no_components': 64, 'learning_rate': 0.5, 'item_alpha': 0.1, 'user_alpha': 0.1, 'max_sampled': 10, 'loss': 'warp'}\n",
      "Result: train_precision = 0.184221088886261, test_precision = 0.0018779343226924539\n",
      "Step 430 of 486\n",
      "Parameters: {'no_components': 64, 'learning_rate': 0.5, 'item_alpha': 0.1, 'user_alpha': 0.1, 'max_sampled': 10, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.004325190093368292, test_precision = 0.004068857524544001\n",
      "Step 431 of 486\n",
      "Parameters: {'no_components': 64, 'learning_rate': 0.5, 'item_alpha': 0.1, 'user_alpha': 0.1, 'max_sampled': 15, 'loss': 'warp'}\n",
      "Result: train_precision = 0.19158993661403656, test_precision = 0.002086593536660075\n",
      "Step 432 of 486\n",
      "Parameters: {'no_components': 64, 'learning_rate': 0.5, 'item_alpha': 0.1, 'user_alpha': 0.1, 'max_sampled': 15, 'loss': 'bpr'}\n",
      "Error ocurred, skipping prameter\n",
      "Step 433 of 486\n",
      "Parameters: {'no_components': 64, 'learning_rate': 1, 'item_alpha': 0.001, 'user_alpha': 0.001, 'max_sampled': 5, 'loss': 'warp'}\n",
      "Result: train_precision = 0.05927112698554993, test_precision = 0.0019822639878839254\n",
      "Step 434 of 486\n",
      "Parameters: {'no_components': 64, 'learning_rate': 1, 'item_alpha': 0.001, 'user_alpha': 0.001, 'max_sampled': 5, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.1423308104276657, test_precision = 0.0036515388637781143\n",
      "Step 435 of 486\n",
      "Parameters: {'no_components': 64, 'learning_rate': 1, 'item_alpha': 0.001, 'user_alpha': 0.001, 'max_sampled': 10, 'loss': 'warp'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: train_precision = 0.07705245912075043, test_precision = 0.002921231323853135\n",
      "Step 436 of 486\n",
      "Parameters: {'no_components': 64, 'learning_rate': 1, 'item_alpha': 0.001, 'user_alpha': 0.001, 'max_sampled': 10, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.14409291744232178, test_precision = 0.0012519562151283026\n",
      "Step 437 of 486\n",
      "Parameters: {'no_components': 64, 'learning_rate': 1, 'item_alpha': 0.001, 'user_alpha': 0.001, 'max_sampled': 15, 'loss': 'warp'}\n",
      "Result: train_precision = 0.10997197031974792, test_precision = 0.0029212310910224915\n",
      "Step 438 of 486\n",
      "Parameters: {'no_components': 64, 'learning_rate': 1, 'item_alpha': 0.001, 'user_alpha': 0.001, 'max_sampled': 15, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.14305166900157928, test_precision = 0.0008346374379470944\n",
      "Step 439 of 486\n",
      "Parameters: {'no_components': 64, 'learning_rate': 1, 'item_alpha': 0.001, 'user_alpha': 0.01, 'max_sampled': 5, 'loss': 'warp'}\n",
      "Result: train_precision = 0.09098919481039047, test_precision = 0.0007303077727556229\n",
      "Step 440 of 486\n",
      "Parameters: {'no_components': 64, 'learning_rate': 1, 'item_alpha': 0.001, 'user_alpha': 0.01, 'max_sampled': 5, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.1404085010290146, test_precision = 0.001147626549936831\n",
      "Step 441 of 486\n",
      "Parameters: {'no_components': 64, 'learning_rate': 1, 'item_alpha': 0.001, 'user_alpha': 0.01, 'max_sampled': 10, 'loss': 'warp'}\n",
      "Result: train_precision = 0.07176612317562103, test_precision = 0.01189358439296484\n",
      "Step 442 of 486\n",
      "Parameters: {'no_components': 64, 'learning_rate': 1, 'item_alpha': 0.001, 'user_alpha': 0.01, 'max_sampled': 10, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.14713656902313232, test_precision = 0.0023995828814804554\n",
      "Step 443 of 486\n",
      "Parameters: {'no_components': 64, 'learning_rate': 1, 'item_alpha': 0.001, 'user_alpha': 0.01, 'max_sampled': 15, 'loss': 'warp'}\n",
      "Result: train_precision = 0.18069684505462646, test_precision = 0.0031298906542360783\n",
      "Step 444 of 486\n",
      "Parameters: {'no_components': 64, 'learning_rate': 1, 'item_alpha': 0.001, 'user_alpha': 0.01, 'max_sampled': 15, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.2927513122558594, test_precision = 0.0016692748758941889\n",
      "Step 445 of 486\n",
      "Parameters: {'no_components': 64, 'learning_rate': 1, 'item_alpha': 0.001, 'user_alpha': 0.1, 'max_sampled': 5, 'loss': 'warp'}\n",
      "Result: train_precision = 0.08001602441072464, test_precision = 0.0027125715278089046\n",
      "Step 446 of 486\n",
      "Parameters: {'no_components': 64, 'learning_rate': 1, 'item_alpha': 0.001, 'user_alpha': 0.1, 'max_sampled': 5, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.13960754871368408, test_precision = 0.001147626549936831\n",
      "Step 447 of 486\n",
      "Parameters: {'no_components': 64, 'learning_rate': 1, 'item_alpha': 0.001, 'user_alpha': 0.1, 'max_sampled': 10, 'loss': 'warp'}\n",
      "Result: train_precision = 0.10596717894077301, test_precision = 0.0027125717606395483\n",
      "Step 448 of 486\n",
      "Parameters: {'no_components': 64, 'learning_rate': 1, 'item_alpha': 0.001, 'user_alpha': 0.1, 'max_sampled': 10, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.15538647770881653, test_precision = 0.0009389671613462269\n",
      "Step 449 of 486\n",
      "Parameters: {'no_components': 64, 'learning_rate': 1, 'item_alpha': 0.001, 'user_alpha': 0.1, 'max_sampled': 15, 'loss': 'warp'}\n",
      "Result: train_precision = 0.116299569606781, test_precision = 0.003442879533395171\n",
      "Step 450 of 486\n",
      "Parameters: {'no_components': 64, 'learning_rate': 1, 'item_alpha': 0.001, 'user_alpha': 0.1, 'max_sampled': 15, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.13952744007110596, test_precision = 0.0016692748758941889\n",
      "Step 451 of 486\n",
      "Parameters: {'no_components': 64, 'learning_rate': 1, 'item_alpha': 0.01, 'user_alpha': 0.001, 'max_sampled': 5, 'loss': 'warp'}\n",
      "Result: train_precision = 0.1860632747411728, test_precision = 0.002086593536660075\n",
      "Step 452 of 486\n",
      "Parameters: {'no_components': 64, 'learning_rate': 1, 'item_alpha': 0.01, 'user_alpha': 0.001, 'max_sampled': 5, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.14745695888996124, test_precision = 0.0016692748758941889\n",
      "Step 453 of 486\n",
      "Parameters: {'no_components': 64, 'learning_rate': 1, 'item_alpha': 0.01, 'user_alpha': 0.001, 'max_sampled': 10, 'loss': 'warp'}\n",
      "Result: train_precision = 0.1038045734167099, test_precision = 0.0027125717606395483\n",
      "Step 454 of 486\n",
      "Parameters: {'no_components': 64, 'learning_rate': 1, 'item_alpha': 0.01, 'user_alpha': 0.001, 'max_sampled': 10, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.14849820733070374, test_precision = 0.002503912430256605\n",
      "Step 455 of 486\n",
      "Parameters: {'no_components': 64, 'learning_rate': 1, 'item_alpha': 0.01, 'user_alpha': 0.001, 'max_sampled': 15, 'loss': 'warp'}\n",
      "Result: train_precision = 0.2118542194366455, test_precision = 0.002503912430256605\n",
      "Step 456 of 486\n",
      "Parameters: {'no_components': 64, 'learning_rate': 1, 'item_alpha': 0.01, 'user_alpha': 0.001, 'max_sampled': 15, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.14489388465881348, test_precision = 0.0032342199701815844\n",
      "Step 457 of 486\n",
      "Parameters: {'no_components': 64, 'learning_rate': 1, 'item_alpha': 0.01, 'user_alpha': 0.01, 'max_sampled': 5, 'loss': 'warp'}\n",
      "Result: train_precision = 0.07889467477798462, test_precision = 0.0028169015422463417\n",
      "Step 458 of 486\n",
      "Parameters: {'no_components': 64, 'learning_rate': 1, 'item_alpha': 0.01, 'user_alpha': 0.01, 'max_sampled': 5, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.14585502445697784, test_precision = 0.002295253099873662\n",
      "Step 459 of 486\n",
      "Parameters: {'no_components': 64, 'learning_rate': 1, 'item_alpha': 0.01, 'user_alpha': 0.01, 'max_sampled': 10, 'loss': 'warp'}\n",
      "Result: train_precision = 0.0761714056134224, test_precision = 0.0027125715278089046\n",
      "Step 460 of 486\n",
      "Parameters: {'no_components': 64, 'learning_rate': 1, 'item_alpha': 0.01, 'user_alpha': 0.01, 'max_sampled': 10, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.1460152268409729, test_precision = 0.0029212310910224915\n",
      "Step 461 of 486\n",
      "Parameters: {'no_components': 64, 'learning_rate': 1, 'item_alpha': 0.01, 'user_alpha': 0.01, 'max_sampled': 15, 'loss': 'warp'}\n",
      "Result: train_precision = 0.21193432807922363, test_precision = 0.0033385497517883778\n",
      "Step 462 of 486\n",
      "Parameters: {'no_components': 64, 'learning_rate': 1, 'item_alpha': 0.01, 'user_alpha': 0.01, 'max_sampled': 15, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.14641571044921875, test_precision = 0.002295253099873662\n",
      "Step 463 of 486\n",
      "Parameters: {'no_components': 64, 'learning_rate': 1, 'item_alpha': 0.01, 'user_alpha': 0.1, 'max_sampled': 5, 'loss': 'warp'}\n",
      "Result: train_precision = 0.2509411573410034, test_precision = 0.0015649452107027173\n",
      "Step 464 of 486\n",
      "Parameters: {'no_components': 64, 'learning_rate': 1, 'item_alpha': 0.01, 'user_alpha': 0.1, 'max_sampled': 5, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.1513015627861023, test_precision = 0.0028169015422463417\n",
      "Step 465 of 486\n",
      "Parameters: {'no_components': 64, 'learning_rate': 1, 'item_alpha': 0.01, 'user_alpha': 0.1, 'max_sampled': 10, 'loss': 'warp'}\n",
      "Result: train_precision = 0.1770925223827362, test_precision = 0.0015649452107027173\n",
      "Step 466 of 486\n",
      "Parameters: {'no_components': 64, 'learning_rate': 1, 'item_alpha': 0.01, 'user_alpha': 0.1, 'max_sampled': 10, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.20296357572078705, test_precision = 0.003964527975767851\n",
      "Step 467 of 486\n",
      "Parameters: {'no_components': 64, 'learning_rate': 1, 'item_alpha': 0.01, 'user_alpha': 0.1, 'max_sampled': 15, 'loss': 'warp'}\n",
      "Result: train_precision = 0.1728474199771881, test_precision = 0.0012519562151283026\n",
      "Step 468 of 486\n",
      "Parameters: {'no_components': 64, 'learning_rate': 1, 'item_alpha': 0.01, 'user_alpha': 0.1, 'max_sampled': 15, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.17316780984401703, test_precision = 0.0016692748758941889\n",
      "Step 469 of 486\n",
      "Parameters: {'no_components': 64, 'learning_rate': 1, 'item_alpha': 0.1, 'user_alpha': 0.001, 'max_sampled': 5, 'loss': 'warp'}\n",
      "Result: train_precision = 0.16764117777347565, test_precision = 0.0028169015422463417\n",
      "Step 470 of 486\n",
      "Parameters: {'no_components': 64, 'learning_rate': 1, 'item_alpha': 0.1, 'user_alpha': 0.001, 'max_sampled': 5, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.1786944568157196, test_precision = 0.0013562857639044523\n",
      "Step 471 of 486\n",
      "Parameters: {'no_components': 64, 'learning_rate': 1, 'item_alpha': 0.1, 'user_alpha': 0.001, 'max_sampled': 10, 'loss': 'warp'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: train_precision = 0.15194234251976013, test_precision = 0.0021909233182668686\n",
      "Step 472 of 486\n",
      "Parameters: {'no_components': 64, 'learning_rate': 1, 'item_alpha': 0.1, 'user_alpha': 0.001, 'max_sampled': 10, 'loss': 'bpr'}\n",
      "Result: train_precision = 0.1892671287059784, test_precision = 0.0010432967683300376\n",
      "Step 473 of 486\n",
      "Parameters: {'no_components': 64, 'learning_rate': 1, 'item_alpha': 0.1, 'user_alpha': 0.001, 'max_sampled': 15, 'loss': 'warp'}\n",
      "Result: train_precision = 0.16123349964618683, test_precision = 0.0019822639878839254\n",
      "Step 474 of 486\n",
      "Parameters: {'no_components': 64, 'learning_rate': 1, 'item_alpha': 0.1, 'user_alpha': 0.001, 'max_sampled': 15, 'loss': 'bpr'}\n",
      "Error ocurred, skipping prameter\n",
      "Step 475 of 486\n",
      "Parameters: {'no_components': 64, 'learning_rate': 1, 'item_alpha': 0.1, 'user_alpha': 0.01, 'max_sampled': 5, 'loss': 'warp'}\n",
      "Result: train_precision = 0.152102530002594, test_precision = 0.0019822639878839254\n",
      "Step 476 of 486\n",
      "Parameters: {'no_components': 64, 'learning_rate': 1, 'item_alpha': 0.1, 'user_alpha': 0.01, 'max_sampled': 5, 'loss': 'bpr'}\n",
      "Error ocurred, skipping prameter\n",
      "Step 477 of 486\n",
      "Parameters: {'no_components': 64, 'learning_rate': 1, 'item_alpha': 0.1, 'user_alpha': 0.01, 'max_sampled': 10, 'loss': 'warp'}\n",
      "Result: train_precision = 0.1712455153465271, test_precision = 0.0019822639878839254\n",
      "Step 478 of 486\n",
      "Parameters: {'no_components': 64, 'learning_rate': 1, 'item_alpha': 0.1, 'user_alpha': 0.01, 'max_sampled': 10, 'loss': 'bpr'}\n",
      "Error ocurred, skipping prameter\n",
      "Step 479 of 486\n",
      "Parameters: {'no_components': 64, 'learning_rate': 1, 'item_alpha': 0.1, 'user_alpha': 0.01, 'max_sampled': 15, 'loss': 'warp'}\n",
      "Result: train_precision = 0.2033640593290329, test_precision = 0.0016692751087248325\n",
      "Step 480 of 486\n",
      "Parameters: {'no_components': 64, 'learning_rate': 1, 'item_alpha': 0.1, 'user_alpha': 0.01, 'max_sampled': 15, 'loss': 'bpr'}\n",
      "Error ocurred, skipping prameter\n",
      "Step 481 of 486\n",
      "Parameters: {'no_components': 64, 'learning_rate': 1, 'item_alpha': 0.1, 'user_alpha': 0.1, 'max_sampled': 5, 'loss': 'warp'}\n",
      "Error ocurred, skipping prameter\n",
      "Step 482 of 486\n",
      "Parameters: {'no_components': 64, 'learning_rate': 1, 'item_alpha': 0.1, 'user_alpha': 0.1, 'max_sampled': 5, 'loss': 'bpr'}\n",
      "Error ocurred, skipping prameter\n",
      "Step 483 of 486\n",
      "Parameters: {'no_components': 64, 'learning_rate': 1, 'item_alpha': 0.1, 'user_alpha': 0.1, 'max_sampled': 10, 'loss': 'warp'}\n",
      "Error ocurred, skipping prameter\n",
      "Step 484 of 486\n",
      "Parameters: {'no_components': 64, 'learning_rate': 1, 'item_alpha': 0.1, 'user_alpha': 0.1, 'max_sampled': 10, 'loss': 'bpr'}\n",
      "Error ocurred, skipping prameter\n",
      "Step 485 of 486\n",
      "Parameters: {'no_components': 64, 'learning_rate': 1, 'item_alpha': 0.1, 'user_alpha': 0.1, 'max_sampled': 15, 'loss': 'warp'}\n",
      "Result: train_precision = 0.18382059037685394, test_precision = 0.002816901309415698\n",
      "Step 486 of 486\n",
      "Parameters: {'no_components': 64, 'learning_rate': 1, 'item_alpha': 0.1, 'user_alpha': 0.1, 'max_sampled': 15, 'loss': 'bpr'}\n",
      "Error ocurred, skipping prameter\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\"no_components\" : [ 16, 40, 64 ],\n",
    "              \"learning_rate\" : [ 0.05, 0.5, 1],\n",
    "              \"item_alpha\"    : [ 0.001, 0.01, 0.1 ],\n",
    "              \"user_alpha\"    : [ 0.001, 0.01, 0.1 ],\n",
    "              \"max_sampled\"   : [ 5, 10, 15 ],\n",
    "              \"loss\"          : [ \"warp\", \"bpr\"] }\n",
    "              \n",
    "results = calc_precision_for_parameters(param_grid, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parameters</th>\n",
       "      <th>train precision@5</th>\n",
       "      <th>test precision@5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'no_components': 64, 'learning_rate': 1, 'ite...</td>\n",
       "      <td>0.071766</td>\n",
       "      <td>0.011894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'no_components': 64, 'learning_rate': 0.5, 'i...</td>\n",
       "      <td>0.107249</td>\n",
       "      <td>0.008033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'no_components': 40, 'learning_rate': 0.05, '...</td>\n",
       "      <td>0.187425</td>\n",
       "      <td>0.007720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'no_components': 40, 'learning_rate': 0.5, 'i...</td>\n",
       "      <td>0.155066</td>\n",
       "      <td>0.006468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'no_components': 64, 'learning_rate': 0.5, 'i...</td>\n",
       "      <td>0.154746</td>\n",
       "      <td>0.006155</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          parameters  train precision@5  \\\n",
       "0  {'no_components': 64, 'learning_rate': 1, 'ite...           0.071766   \n",
       "0  {'no_components': 64, 'learning_rate': 0.5, 'i...           0.107249   \n",
       "0  {'no_components': 40, 'learning_rate': 0.05, '...           0.187425   \n",
       "0  {'no_components': 40, 'learning_rate': 0.5, 'i...           0.155066   \n",
       "0  {'no_components': 64, 'learning_rate': 0.5, 'i...           0.154746   \n",
       "\n",
       "   test precision@5  \n",
       "0          0.011894  \n",
       "0          0.008033  \n",
       "0          0.007720  \n",
       "0          0.006468  \n",
       "0          0.006155  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.sort_values(by=\"test precision@5\", inplace=True, ascending=False)\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'no_components': 64, 'learning_rate': 1, 'item_alpha': 0.001, 'user_alpha': 0.01, 'max_sampled': 10, 'loss': 'warp'}\n"
     ]
    }
   ],
   "source": [
    "print(f\"Best parameters: {results.iloc[0]['parameters']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
